{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e134303b",
   "metadata": {
    "papermill": {
     "duration": 7.390392,
     "end_time": "2022-11-11T06:12:42.243131",
     "exception": false,
     "start_time": "2022-11-11T06:12:34.852739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.__version__: 4.20.1\n",
      "tokenizers.__version__: 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from distutils.util import strtobool\n",
    "import warnings\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import transformers\n",
    "import tokenizers\n",
    "print(f'transformers.__version__: {transformers.__version__}')\n",
    "print(f'tokenizers.__version__: {tokenizers.__version__}')\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "os.environ['TOKENIZERS_PARALLELISM']='true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898644d3",
   "metadata": {
    "papermill": {
     "duration": 0.005823,
     "end_time": "2022-11-11T06:12:42.255630",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.249807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd528b0",
   "metadata": {
    "papermill": {
     "duration": 0.019257,
     "end_time": "2022-11-11T06:12:42.280934",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.261677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TO_KAGGLE = True\n",
    "    debug = False\n",
    "    file_name = \"018\"\n",
    "    model = 'microsoft/deberta-v3-base'\n",
    "    score_path = \"gs://feedback3/output/scores/scores3.csv\"\n",
    "    #models_path = 'FB3-models'\n",
    "    epochs = 10\n",
    "    patience = 3\n",
    "    competition = 'FB3'\n",
    "    train = True\n",
    "    save_all_models = False\n",
    "    offline = False\n",
    "    apex = True\n",
    "    print_freq = 20\n",
    "    num_workers = 4\n",
    "    loss_func = 'SmoothL1' # 'SmoothL1', 'RMSE'\n",
    "    gradient_checkpointing = True\n",
    "    scheduler = 'cosine'\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5\n",
    "    num_warmup_steps = 0\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    min_lr = 1e-6\n",
    "    #Layer-Wise Learning Rate Decay\n",
    "    llrd = True\n",
    "    layerwise_lr = 5e-5\n",
    "    layerwise_lr_decay = 0.9\n",
    "    layerwise_weight_decay = 0.01\n",
    "    layerwise_adam_epsilon = 1e-6\n",
    "    layerwise_use_bertadam = False\n",
    "    #pooling\n",
    "    pooling = 'attention' # mean, max, min, attention, weightedlayer\n",
    "    layer_start = 4\n",
    "    #init_weight\n",
    "    init_weight = 'normal' # normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal\n",
    "    #re-init\n",
    "    reinit = True\n",
    "    reinit_n = 1\n",
    "    #adversarial\n",
    "    fgm = True\n",
    "#     awp = False\n",
    "    adv_lr = 1\n",
    "    adv_eps = 0.2\n",
    "    unscale = False\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    max_len = 512\n",
    "    weight_decay = 0.01\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed = 42\n",
    "    cv_seed = 42\n",
    "    n_fold = 10\n",
    "    trn_fold = list(range(n_fold))\n",
    "    batch_size = 8\n",
    "    n_targets = 6\n",
    "    gpu_id = 0\n",
    "    device = f'cuda:{gpu_id}'\n",
    "    train_file = '/home/jupyter/feedback-prize-english-language-learning/train.csv'\n",
    "    test_file = '/home/jupyter/feedback-prize-english-language-learning/test.csv'\n",
    "    submission_file = '/home/jupyter/feedback-prize-english-language-learning/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1313d603",
   "metadata": {
    "papermill": {
     "duration": 0.016194,
     "end_time": "2022-11-11T06:12:42.303134",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.286940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Unique model name\n",
    "# if len(CFG.model.split(\"/\")) == 2:\n",
    "#     CFG.identifier = f'{CFG.str_now}-{CFG.model.split(\"/\")[1]}'\n",
    "# else:\n",
    "#     CFG.identifier = f'{CFG.str_now}-{CFG.model}'\n",
    "    \n",
    "# print(CFG.identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244524b",
   "metadata": {
    "papermill": {
     "duration": 0.005802,
     "end_time": "2022-11-11T06:12:42.316843",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.311041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read train and split with MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6941bc3d-4870-4558-8cd1-5517622d90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# datetime\n",
    "# ====================================================\n",
    "t_delta = datetime.timedelta(hours=9)\n",
    "JST = datetime.timezone(t_delta, 'JST')\n",
    "now = datetime.datetime.now(JST)\n",
    "date = now.strftime('%Y%m%d')\n",
    "date2 = now.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# file_path\n",
    "# ====================================================\n",
    "if \"/\" in CFG.model:\n",
    "    model_name = CFG.model.split(\"/\")[1]\n",
    "else:\n",
    "    model_name = CFG.model\n",
    "\n",
    "path =\"/home/jupyter/feedback-prize-english-language-learning/\"\n",
    "if CFG.debug:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/DEBUG/{model_name}/{CFG.file_name}/{date2}/'\n",
    "else:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/{model_name}/{CFG.file_name}/{date2}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47255adf",
   "metadata": {
    "papermill": {
     "duration": 10.294485,
     "end_time": "2022-11-11T06:12:52.617208",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.322723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification==0.1.7 in /opt/conda/lib/python3.7/site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/output/ex/deberta-v3-base/018/202211261205/\n"
     ]
    }
   ],
   "source": [
    "if CFG.train:\n",
    "    CFG.df_train = pd.read_csv(CFG.train_file)\n",
    "    CFG.OUTPUT_DIR = OUTPUT_DIR\n",
    "    CFG.log_filename = CFG.OUTPUT_DIR + 'train'\n",
    "    if CFG.offline:\n",
    "        #TO DO\n",
    "        pass\n",
    "    else:\n",
    "        os.system('pip install iterative-stratification==0.1.7')\n",
    "    #CV\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold    \n",
    "    oof = pd.read_pickle(f\"/home/jupyter/output/oof_df/oof_df_CFG1.pkl\")[[\"text_id\",\"fold\"]]\n",
    "    CFG.df_train = pd.merge(CFG.df_train,oof,how=\"left\",on=\"text_id\")\n",
    "    CFG.df_train['fold'] = CFG.df_train['fold'].astype(int)\n",
    "else:\n",
    "    #TO DO\n",
    "    pass\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0]\n",
    "    if CFG.train:\n",
    "        CFG.df_train = CFG.df_train.sample(n = 100, random_state = CFG.seed).reset_index(drop=True)\n",
    "        \n",
    "os.makedirs(CFG.OUTPUT_DIR, exist_ok=True)    \n",
    "print(CFG.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11682f",
   "metadata": {
    "papermill": {
     "duration": 0.006326,
     "end_time": "2022-11-11T06:12:52.631392",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.625066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75785677",
   "metadata": {
    "papermill": {
     "duration": 0.029511,
     "end_time": "2022-11-11T06:12:52.667341",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.637830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:, i]\n",
    "        y_pred = y_preds[:, i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared = False)\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_logger(filename = CFG.log_filename):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter('%(message)s'))\n",
    "    handler2 = FileHandler(filename = f'{filename}.log')\n",
    "    handler2.setFormatter(Formatter('%(message)s'))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors = None,\n",
    "        add_special_tokens = True,\n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs    \n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs['attention_mask'].sum(axis = 1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n = 1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{int(m)}m {int(s)}s'\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return f'{str(asMinutes(s))} (remain {str(asMinutes(rs))})'\n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, reduction = 'mean', eps = 1e-9):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction = 'none')\n",
    "        self.reduction = reduction\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
    "        if self.reduction == 'none':\n",
    "            loss = loss\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        return loss\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefff92",
   "metadata": {
    "papermill": {
     "duration": 0.006217,
     "end_time": "2022-11-11T06:12:52.680127",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.673910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pooling\n",
    "\n",
    "* Attention pooling (https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678)\n",
    "* WeightedLayerPooling (https://www.kaggle.com/code/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning?scriptVersionId=67176591&cellId=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55c7d23",
   "metadata": {
    "papermill": {
     "duration": 0.026848,
     "end_time": "2022-11-11T06:12:52.713183",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.686335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
    "        mean_embeddings = sum_embeddings/sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class MaxPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        embeddings = last_hidden_state.clone()\n",
    "        embeddings[input_mask_expanded == 0] = -1e4\n",
    "        max_embeddings, _ = torch.max(embeddings, dim = 1)\n",
    "        return max_embeddings\n",
    "    \n",
    "class MinPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        embeddings = last_hidden_state.clone()\n",
    "        embeddings[input_mask_expanded == 0] = 1e-4\n",
    "        min_embeddings, _ = torch.min(embeddings, dim = 1)\n",
    "        return min_embeddings\n",
    "\n",
    "#Attention pooling\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "        nn.Linear(in_dim, in_dim),\n",
    "        nn.LayerNorm(in_dim),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(in_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        w = self.attention(last_hidden_state).float()\n",
    "        w[attention_mask==0]=float('-inf')\n",
    "        w = torch.softmax(w,1)\n",
    "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
    "        return attention_embeddings\n",
    "\n",
    "#There may be a bug in my implementation because it does not work well.\n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, ft_all_layers):\n",
    "        all_layer_embedding = torch.stack(ft_all_layers)\n",
    "        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]\n",
    "\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "\n",
    "        return weighted_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649abb3",
   "metadata": {
    "papermill": {
     "duration": 0.006334,
     "end_time": "2022-11-11T06:12:52.725984",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.719650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fast Gradient Method (FGM)\n",
    "Reference :\n",
    "\n",
    "https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b30761",
   "metadata": {
    "papermill": {
     "duration": 0.01792,
     "end_time": "2022-11-11T06:12:52.750455",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.732535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon = 1., emb_name = 'word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name = 'word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "            self.backup = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52647d6b",
   "metadata": {
    "papermill": {
     "duration": 0.006203,
     "end_time": "2022-11-11T06:12:52.763514",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.757311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train function\n",
    "* FGM\n",
    "* Unscale optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e36764",
   "metadata": {
    "papermill": {
     "duration": 0.021948,
     "end_time": "2022-11-11T06:12:52.792023",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.770075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = CFG.apex)\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    if CFG.fgm:\n",
    "        fgm = FGM(model)\n",
    "#     if CFG.awp:\n",
    "#         awp = AWP(model,\n",
    "#                   optimizer, \n",
    "#                   adv_lr = CFG.adv_lr, \n",
    "#                   adv_eps = CFG.adv_eps, \n",
    "#                   scaler = scaler)\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = CFG.apex):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        if CFG.unscale:\n",
    "            scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        #Fast Gradient Method (FGM)\n",
    "        if CFG.fgm:\n",
    "            fgm.attack()\n",
    "            with torch.cuda.amp.autocast(enabled = CFG.apex):\n",
    "                y_preds = model(inputs)\n",
    "                loss_adv = criterion(y_preds, labels)\n",
    "                loss_adv.backward()\n",
    "            fgm.restore()\n",
    "            \n",
    "        #Adversarial Weight Perturbation (AWP)\n",
    "#         if CFG.awp:\n",
    "#             loss_awp = awp.attack_backward(inputs, labels, attention_mask, step + 1)\n",
    "#             loss_awp.backward()\n",
    "#             awp._restore()\n",
    "        \n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f} '\n",
    "                  'LR: {lr:.8f} '\n",
    "                  .format(epoch + 1, step, len(train_loader), remain = timeSince(start, float(step + 1)/len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]\n",
    "                         )\n",
    "                 )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4dee2",
   "metadata": {
    "papermill": {
     "duration": 0.006085,
     "end_time": "2022-11-11T06:12:52.804243",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.798158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e5d7e26",
   "metadata": {
    "papermill": {
     "duration": 0.018106,
     "end_time": "2022-11-11T06:12:52.828802",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.810696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))\n",
    "                         )\n",
    "                 )\n",
    "    return losses.avg, np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6a997",
   "metadata": {
    "papermill": {
     "duration": 0.006992,
     "end_time": "2022-11-11T06:12:52.844588",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.837596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14590fbc",
   "metadata": {
    "papermill": {
     "duration": 0.015217,
     "end_time": "2022-11-11T06:12:52.866248",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.851031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OUTPUT_DIR: /home/jupyter/output/ex/deberta-v3-base/018/202211261205/\n"
     ]
    }
   ],
   "source": [
    "LOGGER = get_logger()\n",
    "LOGGER.info(f'OUTPUT_DIR: {CFG.OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424df24",
   "metadata": {
    "papermill": {
     "duration": 0.006113,
     "end_time": "2022-11-11T06:12:52.878785",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.872672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a68f01",
   "metadata": {
    "papermill": {
     "duration": 9.761103,
     "end_time": "2022-11-11T06:13:02.646289",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.885186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7bec67ccf3488995776dfb985caa61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 1428\n"
     ]
    }
   ],
   "source": [
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "#CFG.tokenizer.save_pretrained(CFG.OUTPUT_DIR + 'tokenizer')\n",
    "\n",
    "#max_len\n",
    "lengths = []\n",
    "tk0 = tqdm(CFG.df_train['full_text'].fillna('').values, total = len(CFG.df_train))\n",
    "for text in tk0:\n",
    "    length = len(CFG.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "CFG.max_len = max(lengths) + 2\n",
    "LOGGER.info(f'max_len: {CFG.max_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d92867",
   "metadata": {
    "papermill": {
     "duration": 0.006808,
     "end_time": "2022-11-11T06:13:02.660860",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.654052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bfd3979",
   "metadata": {
    "papermill": {
     "duration": 0.017173,
     "end_time": "2022-11-11T06:13:02.685013",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.667840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FB3TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['full_text'].values\n",
    "        self.labels = df[cfg.target_cols].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5d446",
   "metadata": {
    "papermill": {
     "duration": 0.00666,
     "end_time": "2022-11-11T06:13:02.698928",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.692268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "\n",
    "* Initializing module (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal) \n",
    "* Freeze lower layer when you use large model (v2-xlarge, funnnel, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7d3ec1",
   "metadata": {
    "papermill": {
     "duration": 0.034698,
     "end_time": "2022-11-11T06:13:02.740521",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.705823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FB3Model(nn.Module):\n",
    "    def __init__(self, CFG, config_path = None, pretrained = False):\n",
    "        super().__init__()\n",
    "        self.CFG = CFG\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(CFG.model, ouput_hidden_states = True)\n",
    "            #self.config.save_pretrained(CFG.OUTPUT_DIR + 'config')\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "            \n",
    "        LOGGER.info(self.config)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(CFG.model, config=self.config)\n",
    "            #self.model.save_pretrained(CFG.OUTPUT_DIR + 'model')\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "            \n",
    "        if self.CFG.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "            \n",
    "        if CFG.pooling == 'mean':\n",
    "            self.pool = MeanPooling()\n",
    "        elif CFG.pooling == 'max':\n",
    "            self.pool = MaxPooling()\n",
    "        elif CFG.pooling == 'min':\n",
    "            self.pool = MinPooling()\n",
    "        elif CFG.pooling == 'attention':\n",
    "            self.pool = AttentionPooling(self.config.hidden_size)\n",
    "        elif CFG.pooling == 'weightedlayer':\n",
    "            self.pool = WeightedLayerPooling(self.config.num_hidden_layers, layer_start = CFG.layer_start, layer_weights = None)        \n",
    "        \n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.CFG.n_targets)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if 'deberta-v2-xxlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:24].requires_grad_(False)\n",
    "        if 'deberta-v2-xlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:12].requires_grad_(False)\n",
    "        if 'funnel-transformer-xlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.blocks[:1].requires_grad_(False)\n",
    "        if 'funnel-transformer-large' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.blocks[:1].requires_grad_(False)\n",
    "        if 'deberta-large' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:16].requires_grad_(False)\n",
    "        if 'deberta-xlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:36].requires_grad_(False)\n",
    "            \n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        if CFG.pooling != 'weightedlayer':\n",
    "            last_hidden_states = outputs[0]\n",
    "            feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        else:\n",
    "            all_layer_embeddings = outputs[1]\n",
    "            feature = self.pool(all_layer_embeddings)\n",
    "            \n",
    "        return feature\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        outout = self.fc(feature)\n",
    "        return outout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778f3e5",
   "metadata": {
    "papermill": {
     "duration": 0.007378,
     "end_time": "2022-11-11T06:13:02.754997",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.747619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "* Re-initializing upper layer (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal) \n",
    "* Layer-Wise Learning Rate Dacay (https://www.kaggle.com/code/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning?scriptVersionId=67176591&cellId=29)\n",
    "* Loss function, SmoothL1 or RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f07471",
   "metadata": {
    "papermill": {
     "duration": 0.044129,
     "end_time": "2022-11-11T06:13:02.806409",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.762280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def re_initializing_layer(model, config, layer_num):\n",
    "    for module in model.model.encoder.layer[-layer_num:].modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data) \n",
    "                \n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    return model   \n",
    "\n",
    "def train_loop(folds, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    \n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop = True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop = True)\n",
    "    valid_labels = valid_folds[CFG.target_cols].values\n",
    "    \n",
    "    train_dataset = FB3TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = FB3TrainDataset(CFG, valid_folds)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size = CFG.batch_size,\n",
    "                              shuffle = True, \n",
    "                              num_workers = CFG.num_workers,\n",
    "                              pin_memory = True, \n",
    "                              drop_last = True\n",
    "                             )\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size = CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "\n",
    "    model = FB3Model(CFG, config_path = None, pretrained = True)\n",
    "    if CFG.reinit:\n",
    "        model = re_initializing_layer(model, model.config, CFG.reinit_n)\n",
    "        \n",
    "    #os.makedirs(CFG.OUTPUT_DIR + 'config/', exist_ok = True)\n",
    "    #torch.save(model.config, CFG.OUTPUT_DIR + 'config/config.pth')\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    def get_optimizer_params(model,\n",
    "                             encoder_lr,\n",
    "                             decoder_lr,\n",
    "                             weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr,\n",
    "             'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr,\n",
    "             'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr,\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    \n",
    "    #llrd\n",
    "    def get_optimizer_grouped_parameters(model, \n",
    "                                         layerwise_lr,\n",
    "                                         layerwise_weight_decay,\n",
    "                                         layerwise_lr_decay):\n",
    "        \n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        # initialize lr for task specific layer\n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "                                         \"weight_decay\": 0.0,\n",
    "                                         \"lr\": layerwise_lr,\n",
    "                                        },]\n",
    "        # initialize lrs for every layer\n",
    "        layers = [model.model.embeddings] + list(model.model.encoder.layer)\n",
    "        layers.reverse()\n",
    "        lr = layerwise_lr\n",
    "        for layer in layers:\n",
    "            optimizer_grouped_parameters += [{\"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                                              \"weight_decay\": layerwise_weight_decay,\n",
    "                                              \"lr\": lr,\n",
    "                                             },\n",
    "                                             {\"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                                              \"weight_decay\": 0.0,\n",
    "                                              \"lr\": lr,\n",
    "                                             },]\n",
    "            lr *= layerwise_lr_decay\n",
    "        return optimizer_grouped_parameters\n",
    "    \n",
    "    if CFG.llrd:\n",
    "        from transformers import AdamW\n",
    "        grouped_optimizer_params = get_optimizer_grouped_parameters(model, \n",
    "                                                                    CFG.layerwise_lr, \n",
    "                                                                    CFG.layerwise_weight_decay, \n",
    "                                                                    CFG.layerwise_lr_decay)\n",
    "        optimizer = AdamW(grouped_optimizer_params,\n",
    "                          lr = CFG.layerwise_lr,\n",
    "                          eps = CFG.layerwise_adam_epsilon,\n",
    "                          correct_bias = not CFG.layerwise_use_bertadam)\n",
    "    else:\n",
    "        from torch.optim import AdamW\n",
    "        optimizer_parameters = get_optimizer_params(model,\n",
    "                                                    encoder_lr=CFG.encoder_lr, \n",
    "                                                    decoder_lr=CFG.decoder_lr,\n",
    "                                                    weight_decay=CFG.weight_decay)\n",
    "        optimizer = AdamW(optimizer_parameters, \n",
    "                          lr=CFG.encoder_lr,\n",
    "                          eps=CFG.eps,\n",
    "                          betas=CFG.betas)\n",
    "    \n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, \n",
    "                num_warmup_steps = cfg.num_warmup_steps, \n",
    "                num_training_steps = num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, \n",
    "                num_warmup_steps = cfg.num_warmup_steps, \n",
    "                num_training_steps = num_train_steps,\n",
    "                num_cycles = cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "    \n",
    "    if CFG.loss_func == 'SmoothL1':\n",
    "        criterion = nn.SmoothL1Loss(reduction='mean')\n",
    "    elif CFG.loss_func == 'RMSE':\n",
    "        criterion = RMSELoss(reduction='mean')\n",
    "    \n",
    "    best_score = np.inf\n",
    "    best_train_loss = np.inf\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    epoch_list = []\n",
    "    epoch_avg_loss_list = []\n",
    "    epoch_avg_val_loss_list = []\n",
    "    epoch_score_list = []\n",
    "    epoch_scores_list = []\n",
    "    patience = CFG.patience\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        \n",
    "        # scoring\n",
    "        score, scores = get_score(valid_labels, predictions)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
    "        \n",
    "        epoch_list.append(epoch+1)\n",
    "        epoch_avg_loss_list.append(avg_loss)\n",
    "        epoch_avg_val_loss_list.append(avg_val_loss)\n",
    "        epoch_score_list.append(score)\n",
    "        epoch_scores_list.append(scores)\n",
    "        \n",
    "        if best_score > score:\n",
    "            patience = CFG.patience\n",
    "            best_score = score\n",
    "            best_train_loss = avg_loss\n",
    "            best_val_loss = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience<=0:\n",
    "                break\n",
    "            \n",
    "        if CFG.save_all_models:\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_epoch{epoch + 1}.pth\")\n",
    "\n",
    "    predictions = torch.load(CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location = torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "    \n",
    "    df_epoch = pd.DataFrame({'epoch' : epoch_list,\n",
    "                             'MCRMSE' : epoch_score_list,\n",
    "                             'train_loss' : epoch_avg_loss_list, \n",
    "                             'val_loss' : epoch_avg_val_loss_list})\n",
    "    df_scores = pd.DataFrame(epoch_scores_list)\n",
    "    df_scores.columns = CFG.target_cols\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return best_train_loss, best_val_loss, valid_folds, pd.concat([df_epoch, df_scores], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188efa9",
   "metadata": {
    "papermill": {
     "duration": 0.00738,
     "end_time": "2022-11-11T06:13:02.821185",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.813805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f247e098",
   "metadata": {
    "papermill": {
     "duration": 0.02245,
     "end_time": "2022-11-11T06:13:02.850607",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.828157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_result(oof_df, fold, best_train_loss, best_val_loss):\n",
    "    labels = oof_df[CFG.target_cols].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
    "    score, scores = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
    "    _output_log = pd.DataFrame([f\"{model_name}-{CFG.file_name}\", CFG.model, CFG.cv_seed, CFG.seed, fold, 'best', score, best_train_loss, best_val_loss] + scores).T\n",
    "    _output_log.columns = ['file', 'model', 'cv_seed', 'seed', 'fold', 'epoch', 'MCRMSE', 'train_loss', 'val_loss'] + CFG.target_cols\n",
    "    return _output_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517f653-0521-4402-813c-2c9e5dcb98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/440] Elapsed 0m 4s (remain 34m 0s) Loss: 2.2695(2.2695) Grad: inf LR: 0.00005000 \n",
      "Epoch: [1][20/440] Elapsed 1m 19s (remain 26m 30s) Loss: 0.2270(1.0698) Grad: 138387.9219 LR: 0.00005000 \n",
      "Epoch: [1][40/440] Elapsed 2m 38s (remain 25m 45s) Loss: 0.2772(0.6534) Grad: 132777.1094 LR: 0.00004999 \n",
      "Epoch: [1][60/440] Elapsed 3m 48s (remain 23m 40s) Loss: 0.1343(0.4993) Grad: 84122.3438 LR: 0.00004998 \n",
      "Epoch: [1][80/440] Elapsed 4m 51s (remain 21m 31s) Loss: 0.1921(0.4116) Grad: 87729.5469 LR: 0.00004996 \n",
      "Epoch: [1][100/440] Elapsed 5m 54s (remain 19m 48s) Loss: 0.1949(0.3570) Grad: 179243.4688 LR: 0.00004994 \n",
      "Epoch: [1][120/440] Elapsed 7m 3s (remain 18m 36s) Loss: 0.0897(0.3185) Grad: 110793.8281 LR: 0.00004991 \n",
      "Epoch: [1][140/440] Elapsed 8m 16s (remain 17m 33s) Loss: 0.1277(0.2924) Grad: 145824.0000 LR: 0.00004987 \n",
      "Epoch: [1][160/440] Elapsed 9m 16s (remain 16m 4s) Loss: 0.1263(0.2734) Grad: 103702.2891 LR: 0.00004984 \n",
      "Epoch: [1][180/440] Elapsed 10m 29s (remain 15m 1s) Loss: 0.1123(0.2564) Grad: 114068.0312 LR: 0.00004979 \n",
      "Epoch: [1][200/440] Elapsed 11m 31s (remain 13m 42s) Loss: 0.1856(0.2447) Grad: 194704.2656 LR: 0.00004974 \n",
      "Epoch: [1][220/440] Elapsed 12m 38s (remain 12m 31s) Loss: 0.1536(0.2356) Grad: 159981.9688 LR: 0.00004969 \n",
      "Epoch: [1][240/440] Elapsed 13m 43s (remain 11m 20s) Loss: 0.0751(0.2263) Grad: 56973.4297 LR: 0.00004963 \n",
      "Epoch: [1][260/440] Elapsed 15m 14s (remain 10m 27s) Loss: 0.1440(0.2190) Grad: 156590.7656 LR: 0.00004957 \n",
      "Epoch: [1][280/440] Elapsed 16m 21s (remain 9m 15s) Loss: 0.1068(0.2118) Grad: 71646.9453 LR: 0.00004950 \n",
      "Epoch: [1][300/440] Elapsed 17m 18s (remain 7m 59s) Loss: 0.1092(0.2048) Grad: 88969.1250 LR: 0.00004942 \n",
      "Epoch: [1][320/440] Elapsed 18m 22s (remain 6m 48s) Loss: 0.1304(0.1996) Grad: 153097.8125 LR: 0.00004935 \n",
      "Epoch: [1][340/440] Elapsed 19m 31s (remain 5m 40s) Loss: 0.0885(0.1953) Grad: 164196.6406 LR: 0.00004926 \n",
      "Epoch: [1][360/440] Elapsed 20m 45s (remain 4m 32s) Loss: 0.0917(0.1912) Grad: 32662.7129 LR: 0.00004917 \n",
      "Epoch: [1][380/440] Elapsed 21m 43s (remain 3m 21s) Loss: 0.0625(0.1873) Grad: 34065.6406 LR: 0.00004908 \n",
      "Epoch: [1][400/440] Elapsed 22m 48s (remain 2m 13s) Loss: 0.1470(0.1846) Grad: 154237.5781 LR: 0.00004898 \n",
      "Epoch: [1][420/440] Elapsed 23m 50s (remain 1m 4s) Loss: 0.1031(0.1818) Grad: 103502.7031 LR: 0.00004888 \n",
      "Epoch: [1][439/440] Elapsed 25m 12s (remain 0m 0s) Loss: 0.1431(0.1792) Grad: 99985.7891 LR: 0.00004878 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1006(0.1006) \n",
      "EVAL: [20/25] Elapsed 0m 49s (remain 0m 9s) Loss: 0.1233(0.1046) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.1792  avg_val_loss: 0.1062  time: 1569s\n",
      "Epoch 1 - Score: 0.4615  Scores: [0.497933357925829, 0.4580529392347574, 0.4377707520117906, 0.43194534715514077, 0.486689103840643, 0.45686170006645876]\n",
      "Epoch 1 - Save Best Score: 0.4615 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 56s (remain 0m 0s) Loss: 0.1272(0.1062) \n",
      "Epoch: [2][0/440] Elapsed 0m 2s (remain 20m 3s) Loss: 0.0749(0.0749) Grad: 91526.0547 LR: 0.00004877 \n",
      "Epoch: [2][20/440] Elapsed 1m 5s (remain 21m 41s) Loss: 0.1776(0.1016) Grad: 275864.6250 LR: 0.00004866 \n",
      "Epoch: [2][40/440] Elapsed 2m 13s (remain 21m 38s) Loss: 0.0973(0.0994) Grad: 141658.9219 LR: 0.00004854 \n",
      "Epoch: [2][60/440] Elapsed 3m 14s (remain 20m 5s) Loss: 0.0982(0.1003) Grad: 169433.0000 LR: 0.00004842 \n",
      "Epoch: [2][80/440] Elapsed 4m 29s (remain 19m 56s) Loss: 0.1439(0.1017) Grad: 264769.3125 LR: 0.00004829 \n",
      "Epoch: [2][100/440] Elapsed 5m 42s (remain 19m 10s) Loss: 0.0863(0.1002) Grad: 161598.4375 LR: 0.00004816 \n",
      "Epoch: [2][120/440] Elapsed 7m 6s (remain 18m 45s) Loss: 0.1533(0.1042) Grad: 380828.1875 LR: 0.00004802 \n",
      "Epoch: [2][140/440] Elapsed 8m 9s (remain 17m 18s) Loss: 0.0914(0.1035) Grad: 74954.7891 LR: 0.00004788 \n",
      "Epoch: [2][160/440] Elapsed 9m 32s (remain 16m 32s) Loss: 0.1432(0.1052) Grad: 271548.8438 LR: 0.00004773 \n",
      "Epoch: [2][180/440] Elapsed 10m 44s (remain 15m 22s) Loss: 0.0628(0.1050) Grad: 124120.9297 LR: 0.00004758 \n",
      "Epoch: [2][200/440] Elapsed 12m 1s (remain 14m 18s) Loss: 0.1428(0.1072) Grad: 368816.8125 LR: 0.00004743 \n",
      "Epoch: [2][220/440] Elapsed 13m 10s (remain 13m 3s) Loss: 0.1150(0.1082) Grad: 252500.1094 LR: 0.00004727 \n",
      "Epoch: [2][240/440] Elapsed 14m 22s (remain 11m 52s) Loss: 0.0871(0.1077) Grad: 168737.3750 LR: 0.00004710 \n",
      "Epoch: [2][260/440] Elapsed 15m 32s (remain 10m 39s) Loss: 0.1016(0.1081) Grad: 108146.9688 LR: 0.00004693 \n",
      "Epoch: [2][280/440] Elapsed 16m 35s (remain 9m 23s) Loss: 0.0901(0.1084) Grad: 143296.9375 LR: 0.00004676 \n",
      "Epoch: [2][300/440] Elapsed 17m 49s (remain 8m 13s) Loss: 0.0990(0.1094) Grad: 98863.0859 LR: 0.00004658 \n",
      "Epoch: [2][320/440] Elapsed 18m 48s (remain 6m 58s) Loss: 0.2310(0.1097) Grad: 470003.8438 LR: 0.00004640 \n",
      "Epoch: [2][340/440] Elapsed 20m 1s (remain 5m 48s) Loss: 0.1821(0.1114) Grad: 262663.3750 LR: 0.00004621 \n",
      "Epoch: [2][360/440] Elapsed 21m 6s (remain 4m 37s) Loss: 0.1264(0.1112) Grad: 173058.4219 LR: 0.00004602 \n",
      "Epoch: [2][380/440] Elapsed 22m 24s (remain 3m 28s) Loss: 0.1071(0.1110) Grad: 166148.5625 LR: 0.00004583 \n",
      "Epoch: [2][400/440] Elapsed 23m 22s (remain 2m 16s) Loss: 0.0922(0.1106) Grad: 119202.6875 LR: 0.00004563 \n",
      "Epoch: [2][420/440] Elapsed 24m 31s (remain 1m 6s) Loss: 0.1263(0.1105) Grad: 125459.6719 LR: 0.00004542 \n",
      "Epoch: [2][439/440] Elapsed 25m 31s (remain 0m 0s) Loss: 0.0970(0.1104) Grad: 175087.0938 LR: 0.00004523 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1049(0.1049) \n",
      "EVAL: [20/25] Elapsed 0m 49s (remain 0m 9s) Loss: 0.1131(0.1041) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1104  avg_val_loss: 0.1057  time: 1588s\n",
      "Epoch 2 - Score: 0.4606  Scores: [0.5020590029320753, 0.44002857564349224, 0.46289341631132136, 0.43330339210009633, 0.4776042726685252, 0.4475342264953566]\n",
      "Epoch 2 - Save Best Score: 0.4606 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 56s (remain 0m 0s) Loss: 0.1265(0.1057) \n",
      "Epoch: [3][0/440] Elapsed 0m 2s (remain 15m 43s) Loss: 0.0851(0.0851) Grad: 105872.6875 LR: 0.00004521 \n",
      "Epoch: [3][20/440] Elapsed 1m 13s (remain 24m 27s) Loss: 0.0936(0.1040) Grad: 290185.3438 LR: 0.00004500 \n",
      "Epoch: [3][40/440] Elapsed 2m 20s (remain 22m 43s) Loss: 0.0948(0.1000) Grad: 201676.8125 LR: 0.00004479 \n",
      "Epoch: [3][60/440] Elapsed 3m 28s (remain 21m 34s) Loss: 0.0842(0.0979) Grad: 142457.3906 LR: 0.00004457 \n",
      "Epoch: [3][80/440] Elapsed 4m 35s (remain 20m 23s) Loss: 0.0971(0.0985) Grad: 233256.2812 LR: 0.00004434 \n",
      "Epoch: [3][100/440] Elapsed 5m 36s (remain 18m 48s) Loss: 0.1229(0.1046) Grad: 129880.8594 LR: 0.00004411 \n",
      "Epoch: [3][120/440] Elapsed 6m 43s (remain 17m 42s) Loss: 0.1342(0.1046) Grad: 198779.5625 LR: 0.00004388 \n",
      "Epoch: [3][140/440] Elapsed 8m 2s (remain 17m 4s) Loss: 0.0859(0.1047) Grad: 142926.6250 LR: 0.00004365 \n",
      "Epoch: [3][160/440] Elapsed 8m 54s (remain 15m 26s) Loss: 0.1315(0.1042) Grad: 242556.1094 LR: 0.00004341 \n",
      "Epoch: [3][180/440] Elapsed 10m 15s (remain 14m 40s) Loss: 0.0648(0.1031) Grad: 113041.5000 LR: 0.00004316 \n",
      "Epoch: [3][200/440] Elapsed 11m 25s (remain 13m 35s) Loss: 0.1101(0.1040) Grad: 144431.3438 LR: 0.00004292 \n",
      "Epoch: [3][220/440] Elapsed 12m 42s (remain 12m 35s) Loss: 0.1177(0.1033) Grad: 164336.1250 LR: 0.00004267 \n",
      "Epoch: [3][240/440] Elapsed 13m 38s (remain 11m 15s) Loss: 0.0847(0.1030) Grad: 122038.9531 LR: 0.00004241 \n",
      "Epoch: [3][260/440] Elapsed 14m 56s (remain 10m 14s) Loss: 0.1391(0.1038) Grad: 622604.8125 LR: 0.00004215 \n",
      "Epoch: [3][280/440] Elapsed 16m 18s (remain 9m 13s) Loss: 0.1216(0.1028) Grad: 285030.5000 LR: 0.00004189 \n",
      "Epoch: [3][300/440] Elapsed 17m 27s (remain 8m 3s) Loss: 0.1337(0.1025) Grad: 400411.5938 LR: 0.00004163 \n",
      "Epoch: [3][320/440] Elapsed 18m 31s (remain 6m 51s) Loss: 0.0827(0.1026) Grad: 185302.1562 LR: 0.00004136 \n",
      "Epoch: [3][340/440] Elapsed 19m 48s (remain 5m 44s) Loss: 0.0804(0.1028) Grad: 182759.6719 LR: 0.00004109 \n",
      "Epoch: [3][360/440] Elapsed 21m 5s (remain 4m 37s) Loss: 0.1402(0.1028) Grad: 251115.6875 LR: 0.00004081 \n",
      "Epoch: [3][380/440] Elapsed 22m 22s (remain 3m 27s) Loss: 0.0767(0.1022) Grad: 120361.1875 LR: 0.00004053 \n",
      "Epoch: [3][400/440] Elapsed 23m 22s (remain 2m 16s) Loss: 0.1173(0.1021) Grad: 147774.0312 LR: 0.00004025 \n",
      "Epoch: [3][420/440] Elapsed 24m 37s (remain 1m 6s) Loss: 0.0496(0.1020) Grad: 90481.7500 LR: 0.00003997 \n",
      "Epoch: [3][439/440] Elapsed 25m 36s (remain 0m 0s) Loss: 0.1095(0.1017) Grad: 347124.7812 LR: 0.00003969 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1049(0.1049) \n",
      "EVAL: [20/25] Elapsed 0m 48s (remain 0m 9s) Loss: 0.1297(0.1071) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.1017  avg_val_loss: 0.1081  time: 1592s\n",
      "Epoch 3 - Score: 0.4650  Scores: [0.5065377419168912, 0.45017174883345557, 0.4404302190888805, 0.42220903956865646, 0.5305050826681599, 0.4401421915393284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 56s (remain 0m 0s) Loss: 0.1309(0.1081) \n",
      "Epoch: [4][0/440] Elapsed 0m 4s (remain 36m 15s) Loss: 0.0859(0.0859) Grad: 140206.9531 LR: 0.00003968 \n",
      "Epoch: [4][20/440] Elapsed 1m 14s (remain 24m 51s) Loss: 0.1080(0.0934) Grad: 196579.3594 LR: 0.00003939 \n",
      "Epoch: [4][40/440] Elapsed 2m 34s (remain 25m 4s) Loss: 0.1012(0.0941) Grad: 166399.8750 LR: 0.00003910 \n",
      "Epoch: [4][60/440] Elapsed 3m 34s (remain 22m 12s) Loss: 0.1678(0.0963) Grad: 477854.2188 LR: 0.00003880 \n",
      "Epoch: [4][80/440] Elapsed 4m 35s (remain 20m 19s) Loss: 0.0968(0.0945) Grad: 198452.7969 LR: 0.00003850 \n",
      "Epoch: [4][100/440] Elapsed 5m 45s (remain 19m 20s) Loss: 0.0918(0.0957) Grad: 205710.4062 LR: 0.00003820 \n",
      "Epoch: [4][120/440] Elapsed 6m 55s (remain 18m 15s) Loss: 0.1139(0.0949) Grad: 119073.1016 LR: 0.00003789 \n",
      "Epoch: [4][140/440] Elapsed 7m 58s (remain 16m 54s) Loss: 0.0706(0.0946) Grad: 182033.6250 LR: 0.00003759 \n",
      "Epoch: [4][160/440] Elapsed 8m 59s (remain 15m 34s) Loss: 0.0740(0.0936) Grad: 94611.6484 LR: 0.00003728 \n",
      "Epoch: [4][180/440] Elapsed 10m 16s (remain 14m 41s) Loss: 0.0817(0.0933) Grad: 143507.1094 LR: 0.00003697 \n",
      "Epoch: [4][200/440] Elapsed 11m 26s (remain 13m 36s) Loss: 0.1087(0.0932) Grad: 145859.2812 LR: 0.00003665 \n",
      "Epoch: [4][220/440] Elapsed 12m 27s (remain 12m 20s) Loss: 0.0986(0.0945) Grad: 193150.9688 LR: 0.00003633 \n",
      "Epoch: [4][240/440] Elapsed 13m 33s (remain 11m 12s) Loss: 0.0520(0.0949) Grad: 138763.2812 LR: 0.00003601 \n",
      "Epoch: [4][260/440] Elapsed 14m 39s (remain 10m 3s) Loss: 0.0921(0.0948) Grad: 143695.1562 LR: 0.00003569 \n",
      "Epoch: [4][280/440] Elapsed 15m 57s (remain 9m 1s) Loss: 0.0747(0.0944) Grad: 148593.2812 LR: 0.00003537 \n",
      "Epoch: [4][300/440] Elapsed 16m 56s (remain 7m 49s) Loss: 0.1325(0.0946) Grad: 230492.0938 LR: 0.00003504 \n",
      "Epoch: [4][320/440] Elapsed 18m 9s (remain 6m 43s) Loss: 0.0940(0.0947) Grad: 90228.6250 LR: 0.00003472 \n",
      "Epoch: [4][340/440] Elapsed 19m 20s (remain 5m 37s) Loss: 0.0912(0.0944) Grad: 183673.9844 LR: 0.00003439 \n",
      "Epoch: [4][360/440] Elapsed 20m 33s (remain 4m 29s) Loss: 0.1277(0.0940) Grad: 487194.1562 LR: 0.00003405 \n",
      "Epoch: [4][380/440] Elapsed 21m 49s (remain 3m 22s) Loss: 0.0614(0.0942) Grad: 101118.6953 LR: 0.00003372 \n",
      "Epoch: [4][400/440] Elapsed 23m 1s (remain 2m 14s) Loss: 0.0798(0.0942) Grad: 151617.4531 LR: 0.00003338 \n",
      "Epoch: [4][420/440] Elapsed 24m 14s (remain 1m 5s) Loss: 0.0624(0.0939) Grad: 287516.9375 LR: 0.00003305 \n",
      "Epoch: [4][439/440] Elapsed 25m 29s (remain 0m 0s) Loss: 0.0761(0.0947) Grad: 253291.4844 LR: 0.00003273 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1014(0.1014) \n",
      "EVAL: [20/25] Elapsed 0m 48s (remain 0m 9s) Loss: 0.1111(0.1030) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0947  avg_val_loss: 0.1045  time: 1586s\n",
      "Epoch 4 - Score: 0.4579  Scores: [0.49635157382223305, 0.44389586284287236, 0.43954999322014077, 0.4368815032432967, 0.4836569392193099, 0.44682011138864586]\n",
      "Epoch 4 - Save Best Score: 0.4579 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 56s (remain 0m 0s) Loss: 0.1271(0.1045) \n",
      "Epoch: [5][0/440] Elapsed 0m 5s (remain 42m 44s) Loss: 0.0620(0.0620) Grad: 103446.1250 LR: 0.00003271 \n",
      "Epoch: [5][20/440] Elapsed 1m 22s (remain 27m 23s) Loss: 0.0730(0.0834) Grad: 327441.7188 LR: 0.00003237 \n",
      "Epoch: [5][40/440] Elapsed 2m 26s (remain 23m 46s) Loss: 0.0683(0.0810) Grad: 97659.4531 LR: 0.00003203 \n",
      "Epoch: [5][60/440] Elapsed 3m 31s (remain 21m 56s) Loss: 0.0884(0.0815) Grad: 106604.0938 LR: 0.00003168 \n",
      "Epoch: [5][80/440] Elapsed 4m 39s (remain 20m 39s) Loss: 0.0753(0.0816) Grad: 154218.5312 LR: 0.00003134 \n",
      "Epoch: [5][100/440] Elapsed 5m 57s (remain 20m 0s) Loss: 0.0841(0.0824) Grad: 238409.0625 LR: 0.00003099 \n",
      "Epoch: [5][120/440] Elapsed 7m 4s (remain 18m 40s) Loss: 0.0836(0.0821) Grad: 177140.2500 LR: 0.00003065 \n",
      "Epoch: [5][140/440] Elapsed 8m 14s (remain 17m 28s) Loss: 0.0879(0.0824) Grad: 176347.3281 LR: 0.00003030 \n",
      "Epoch: [5][160/440] Elapsed 9m 24s (remain 16m 17s) Loss: 0.0462(0.0816) Grad: 126248.0547 LR: 0.00002995 \n",
      "Epoch: [5][180/440] Elapsed 10m 40s (remain 15m 16s) Loss: 0.1068(0.0826) Grad: 194824.7812 LR: 0.00002960 \n",
      "Epoch: [5][200/440] Elapsed 11m 49s (remain 14m 3s) Loss: 0.0629(0.0828) Grad: 416966.2812 LR: 0.00002925 \n",
      "Epoch: [5][220/440] Elapsed 12m 50s (remain 12m 43s) Loss: 0.0950(0.0831) Grad: 175232.4844 LR: 0.00002889 \n",
      "Epoch: [5][240/440] Elapsed 14m 5s (remain 11m 38s) Loss: 0.0862(0.0831) Grad: 171223.0156 LR: 0.00002854 \n",
      "Epoch: [5][260/440] Elapsed 15m 5s (remain 10m 20s) Loss: 0.1056(0.0831) Grad: 162950.7500 LR: 0.00002819 \n",
      "Epoch: [5][280/440] Elapsed 16m 19s (remain 9m 14s) Loss: 0.0897(0.0827) Grad: 94560.2891 LR: 0.00002783 \n",
      "Epoch: [5][300/440] Elapsed 17m 25s (remain 8m 2s) Loss: 0.0692(0.0826) Grad: 177348.2031 LR: 0.00002748 \n",
      "Epoch: [5][320/440] Elapsed 18m 29s (remain 6m 51s) Loss: 0.1184(0.0825) Grad: 209887.5781 LR: 0.00002712 \n",
      "Epoch: [5][340/440] Elapsed 19m 46s (remain 5m 44s) Loss: 0.0622(0.0825) Grad: 143218.0312 LR: 0.00002677 \n",
      "Epoch: [5][360/440] Elapsed 20m 59s (remain 4m 35s) Loss: 0.0691(0.0826) Grad: 84874.0000 LR: 0.00002641 \n",
      "Epoch: [5][380/440] Elapsed 22m 19s (remain 3m 27s) Loss: 0.0827(0.0824) Grad: 155472.9219 LR: 0.00002605 \n",
      "Epoch: [5][400/440] Elapsed 23m 30s (remain 2m 17s) Loss: 0.0984(0.0827) Grad: 151819.8281 LR: 0.00002570 \n",
      "Epoch: [5][420/440] Elapsed 24m 36s (remain 1m 6s) Loss: 0.0893(0.0826) Grad: 116572.5859 LR: 0.00002534 \n",
      "Epoch: [5][439/440] Elapsed 25m 37s (remain 0m 0s) Loss: 0.0501(0.0823) Grad: 104354.5859 LR: 0.00002500 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1076(0.1076) \n",
      "EVAL: [20/25] Elapsed 0m 48s (remain 0m 9s) Loss: 0.1090(0.1123) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0823  avg_val_loss: 0.1131  time: 1594s\n",
      "Epoch 5 - Score: 0.4760  Scores: [0.5254026594333728, 0.46081549119107956, 0.4272209124245381, 0.44386539034972533, 0.5357141478016345, 0.4629112701700276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 55s (remain 0m 0s) Loss: 0.1322(0.1131) \n",
      "Epoch: [6][0/440] Elapsed 0m 2s (remain 15m 56s) Loss: 0.0784(0.0784) Grad: 158865.6094 LR: 0.00002498 \n",
      "Epoch: [6][20/440] Elapsed 1m 18s (remain 26m 2s) Loss: 0.0501(0.0759) Grad: 52537.1211 LR: 0.00002463 \n",
      "Epoch: [6][40/440] Elapsed 2m 20s (remain 22m 48s) Loss: 0.0497(0.0719) Grad: 78847.4219 LR: 0.00002427 \n",
      "Epoch: [6][60/440] Elapsed 3m 20s (remain 20m 48s) Loss: 0.0757(0.0699) Grad: 111522.1094 LR: 0.00002391 \n",
      "Epoch: [6][80/440] Elapsed 4m 27s (remain 19m 46s) Loss: 0.0997(0.0713) Grad: 444331.3125 LR: 0.00002355 \n",
      "Epoch: [6][100/440] Elapsed 5m 33s (remain 18m 38s) Loss: 0.0797(0.0722) Grad: 156342.5469 LR: 0.00002320 \n",
      "Epoch: [6][120/440] Elapsed 6m 43s (remain 17m 43s) Loss: 0.0431(0.0711) Grad: 147014.2031 LR: 0.00002284 \n",
      "Epoch: [6][140/440] Elapsed 8m 7s (remain 17m 12s) Loss: 0.0647(0.0704) Grad: 140927.5156 LR: 0.00002249 \n",
      "Epoch: [6][160/440] Elapsed 9m 16s (remain 16m 4s) Loss: 0.0681(0.0703) Grad: 194212.8594 LR: 0.00002213 \n",
      "Epoch: [6][180/440] Elapsed 10m 37s (remain 15m 12s) Loss: 0.0837(0.0702) Grad: 192627.1719 LR: 0.00002178 \n",
      "Epoch: [6][200/440] Elapsed 11m 42s (remain 13m 55s) Loss: 0.0772(0.0702) Grad: 154926.4062 LR: 0.00002142 \n",
      "Epoch: [6][220/440] Elapsed 12m 53s (remain 12m 46s) Loss: 0.0593(0.0706) Grad: 215251.2812 LR: 0.00002107 \n",
      "Epoch: [6][240/440] Elapsed 13m 54s (remain 11m 29s) Loss: 0.0434(0.0701) Grad: 104146.3047 LR: 0.00002072 \n",
      "Epoch: [6][260/440] Elapsed 15m 1s (remain 10m 18s) Loss: 0.0745(0.0702) Grad: 138844.2812 LR: 0.00002037 \n",
      "Epoch: [6][280/440] Elapsed 16m 20s (remain 9m 15s) Loss: 0.0492(0.0705) Grad: 100183.7344 LR: 0.00002002 \n",
      "Epoch: [6][300/440] Elapsed 17m 41s (remain 8m 10s) Loss: 0.0971(0.0706) Grad: 179139.8281 LR: 0.00001967 \n",
      "Epoch: [6][320/440] Elapsed 18m 59s (remain 7m 2s) Loss: 0.0757(0.0703) Grad: 348129.6250 LR: 0.00001932 \n",
      "Epoch: [6][340/440] Elapsed 20m 5s (remain 5m 49s) Loss: 0.0552(0.0702) Grad: 448682.2188 LR: 0.00001897 \n",
      "Epoch: [6][360/440] Elapsed 21m 11s (remain 4m 38s) Loss: 0.0538(0.0704) Grad: 118539.9609 LR: 0.00001863 \n",
      "Epoch: [6][380/440] Elapsed 22m 10s (remain 3m 26s) Loss: 0.0755(0.0702) Grad: 124310.1953 LR: 0.00001828 \n",
      "Epoch: [6][400/440] Elapsed 23m 30s (remain 2m 17s) Loss: 0.0547(0.0701) Grad: 154553.9219 LR: 0.00001794 \n",
      "Epoch: [6][420/440] Elapsed 24m 47s (remain 1m 7s) Loss: 0.0684(0.0699) Grad: 97648.7188 LR: 0.00001760 \n",
      "Epoch: [6][439/440] Elapsed 25m 46s (remain 0m 0s) Loss: 0.0487(0.0696) Grad: 203929.8438 LR: 0.00001727 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1225(0.1225) \n",
      "EVAL: [20/25] Elapsed 0m 49s (remain 0m 9s) Loss: 0.1388(0.1209) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0696  avg_val_loss: 0.1216  time: 1603s\n",
      "Epoch 6 - Score: 0.4937  Scores: [0.5620672456574626, 0.4786949803824272, 0.426770851813223, 0.4741790272816547, 0.5310489776935474, 0.4893168826446271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 56s (remain 0m 0s) Loss: 0.1409(0.1216) \n",
      "Epoch: [7][0/440] Elapsed 0m 4s (remain 32m 8s) Loss: 0.0427(0.0427) Grad: 116048.3594 LR: 0.00001726 \n",
      "Epoch: [7][20/440] Elapsed 1m 11s (remain 23m 55s) Loss: 0.0503(0.0594) Grad: 90980.4688 LR: 0.00001692 \n",
      "Epoch: [7][40/440] Elapsed 2m 42s (remain 26m 25s) Loss: 0.0841(0.0594) Grad: 93334.7578 LR: 0.00001658 \n",
      "Epoch: [7][60/440] Elapsed 3m 38s (remain 22m 36s) Loss: 0.0625(0.0594) Grad: 155003.2969 LR: 0.00001625 \n",
      "Epoch: [7][80/440] Elapsed 4m 40s (remain 20m 42s) Loss: 0.0555(0.0602) Grad: 146547.9062 LR: 0.00001591 \n",
      "Epoch: [7][100/440] Elapsed 5m 57s (remain 20m 0s) Loss: 0.0544(0.0590) Grad: 89495.2656 LR: 0.00001558 \n",
      "Epoch: [7][120/440] Elapsed 7m 5s (remain 18m 40s) Loss: 0.0488(0.0591) Grad: 105176.9141 LR: 0.00001525 \n",
      "Epoch: [7][140/440] Elapsed 8m 4s (remain 17m 7s) Loss: 0.0799(0.0587) Grad: 125500.1562 LR: 0.00001492 \n",
      "Epoch: [7][160/440] Elapsed 9m 15s (remain 16m 3s) Loss: 0.0748(0.0592) Grad: 108187.9219 LR: 0.00001460 \n",
      "Epoch: [7][180/440] Elapsed 10m 26s (remain 14m 57s) Loss: 0.0706(0.0599) Grad: 247503.2500 LR: 0.00001427 \n",
      "Epoch: [7][200/440] Elapsed 11m 37s (remain 13m 49s) Loss: 0.0652(0.0602) Grad: 164465.5000 LR: 0.00001395 \n",
      "Epoch: [7][220/440] Elapsed 12m 38s (remain 12m 31s) Loss: 0.0613(0.0597) Grad: 110831.8672 LR: 0.00001363 \n",
      "Epoch: [7][240/440] Elapsed 13m 48s (remain 11m 24s) Loss: 0.0587(0.0597) Grad: 63121.3359 LR: 0.00001332 \n",
      "Epoch: [7][260/440] Elapsed 15m 1s (remain 10m 18s) Loss: 0.0548(0.0597) Grad: 90010.9453 LR: 0.00001300 \n",
      "Epoch: [7][280/440] Elapsed 16m 13s (remain 9m 10s) Loss: 0.0417(0.0594) Grad: 244435.8438 LR: 0.00001269 \n",
      "Epoch: [7][300/440] Elapsed 17m 28s (remain 8m 4s) Loss: 0.0626(0.0588) Grad: 119112.0781 LR: 0.00001238 \n",
      "Epoch: [7][320/440] Elapsed 18m 43s (remain 6m 56s) Loss: 0.0571(0.0590) Grad: 159729.5312 LR: 0.00001207 \n",
      "Epoch: [7][340/440] Elapsed 19m 48s (remain 5m 44s) Loss: 0.0491(0.0592) Grad: 104081.6250 LR: 0.00001177 \n",
      "Epoch: [7][360/440] Elapsed 21m 1s (remain 4m 35s) Loss: 0.0655(0.0592) Grad: 166363.5938 LR: 0.00001147 \n",
      "Epoch: [7][380/440] Elapsed 22m 15s (remain 3m 26s) Loss: 0.0564(0.0593) Grad: 100524.1719 LR: 0.00001117 \n",
      "Epoch: [7][400/440] Elapsed 23m 28s (remain 2m 16s) Loss: 0.0545(0.0593) Grad: 216656.2656 LR: 0.00001087 \n",
      "Epoch: [7][420/440] Elapsed 24m 39s (remain 1m 6s) Loss: 0.0442(0.0590) Grad: 213049.3438 LR: 0.00001058 \n",
      "Epoch: [7][439/440] Elapsed 25m 38s (remain 0m 0s) Loss: 0.0393(0.0588) Grad: 157848.4531 LR: 0.00001031 \n",
      "EVAL: [0/25] Elapsed 0m 1s (remain 0m 41s) Loss: 0.1035(0.1035) \n",
      "EVAL: [20/25] Elapsed 0m 48s (remain 0m 9s) Loss: 0.1130(0.1099) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0588  avg_val_loss: 0.1115  time: 1595s\n",
      "Epoch 7 - Score: 0.4727  Scores: [0.520489621451889, 0.4564917353293964, 0.42745501665200136, 0.4554431343182676, 0.5141957908735811, 0.462262860241757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 56s (remain 0m 0s) Loss: 0.1349(0.1115) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 0.4579  Scores: [0.49635157382223305, 0.44389586284287236, 0.43954999322014077, 0.4368815032432967, 0.4836569392193099, 0.44682011138864586]\n",
      "========== fold: 1 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/440] Elapsed 0m 3s (remain 23m 25s) Loss: 2.4357(2.4357) Grad: inf LR: 0.00005000 \n",
      "Epoch: [1][20/440] Elapsed 1m 8s (remain 22m 56s) Loss: 0.2112(1.3990) Grad: 107680.7656 LR: 0.00005000 \n",
      "Epoch: [1][40/440] Elapsed 2m 18s (remain 22m 28s) Loss: 0.2247(0.8422) Grad: 73817.8203 LR: 0.00004999 \n",
      "Epoch: [1][60/440] Elapsed 3m 36s (remain 22m 25s) Loss: 0.1771(0.6293) Grad: 96643.8281 LR: 0.00004998 \n",
      "Epoch: [1][80/440] Elapsed 4m 47s (remain 21m 12s) Loss: 0.1262(0.5099) Grad: 109814.9297 LR: 0.00004996 \n",
      "Epoch: [1][100/440] Elapsed 6m 7s (remain 20m 32s) Loss: 0.1151(0.4355) Grad: 61245.5508 LR: 0.00004994 \n",
      "Epoch: [1][120/440] Elapsed 7m 12s (remain 18m 59s) Loss: 0.1929(0.3862) Grad: 119653.7500 LR: 0.00004991 \n",
      "Epoch: [1][140/440] Elapsed 8m 15s (remain 17m 30s) Loss: 0.1310(0.3501) Grad: 114557.4844 LR: 0.00004987 \n",
      "Epoch: [1][160/440] Elapsed 9m 20s (remain 16m 10s) Loss: 0.1491(0.3240) Grad: 173079.8125 LR: 0.00004984 \n",
      "Epoch: [1][180/440] Elapsed 10m 35s (remain 15m 8s) Loss: 0.1225(0.3022) Grad: 64022.7969 LR: 0.00004979 \n",
      "Epoch: [1][200/440] Elapsed 12m 3s (remain 14m 20s) Loss: 0.1181(0.2859) Grad: 49634.2969 LR: 0.00004974 \n",
      "Epoch: [1][220/440] Elapsed 13m 11s (remain 13m 4s) Loss: 0.1441(0.2705) Grad: 66849.1172 LR: 0.00004969 \n",
      "Epoch: [1][240/440] Elapsed 14m 25s (remain 11m 54s) Loss: 0.0732(0.2580) Grad: 59302.9219 LR: 0.00004963 \n",
      "Epoch: [1][260/440] Elapsed 15m 19s (remain 10m 30s) Loss: 0.1006(0.2469) Grad: 91761.2188 LR: 0.00004957 \n",
      "Epoch: [1][280/440] Elapsed 16m 42s (remain 9m 27s) Loss: 0.0772(0.2392) Grad: 71348.4844 LR: 0.00004950 \n",
      "Epoch: [1][300/440] Elapsed 17m 54s (remain 8m 16s) Loss: 0.1299(0.2315) Grad: 91076.1562 LR: 0.00004942 \n",
      "Epoch: [1][320/440] Elapsed 18m 57s (remain 7m 1s) Loss: 0.1308(0.2242) Grad: 131836.8125 LR: 0.00004935 \n",
      "Epoch: [1][340/440] Elapsed 20m 3s (remain 5m 49s) Loss: 0.1443(0.2188) Grad: 58719.9766 LR: 0.00004926 \n",
      "Epoch: [1][360/440] Elapsed 21m 10s (remain 4m 38s) Loss: 0.0872(0.2126) Grad: 72694.0859 LR: 0.00004917 \n",
      "Epoch: [1][380/440] Elapsed 22m 23s (remain 3m 27s) Loss: 0.0891(0.2076) Grad: 51496.4453 LR: 0.00004908 \n",
      "Epoch: [1][400/440] Elapsed 23m 30s (remain 2m 17s) Loss: 0.0641(0.2027) Grad: 48854.0781 LR: 0.00004898 \n",
      "Epoch: [1][420/440] Elapsed 24m 37s (remain 1m 6s) Loss: 0.1216(0.1986) Grad: 57532.5977 LR: 0.00004888 \n",
      "Epoch: [1][439/440] Elapsed 25m 47s (remain 0m 0s) Loss: 0.1222(0.1951) Grad: 55018.2227 LR: 0.00004878 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 0m 54s) Loss: 0.1192(0.1192) \n",
      "EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1072(0.1195) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.1951  avg_val_loss: 0.1190  time: 1600s\n",
      "Epoch 1 - Score: 0.4889  Scores: [0.5517771184942732, 0.47401060279942286, 0.4299918826940122, 0.44616610660127315, 0.5486668916329905, 0.48299980170192264]\n",
      "Epoch 1 - Save Best Score: 0.4889 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0956(0.1190) \n",
      "Epoch: [2][0/440] Elapsed 0m 3s (remain 22m 7s) Loss: 0.0935(0.0935) Grad: 230293.7656 LR: 0.00004877 \n",
      "Epoch: [2][20/440] Elapsed 1m 5s (remain 21m 53s) Loss: 0.0929(0.1101) Grad: 107325.9219 LR: 0.00004866 \n",
      "Epoch: [2][40/440] Elapsed 2m 21s (remain 22m 55s) Loss: 0.0769(0.1053) Grad: 100848.7422 LR: 0.00004854 \n",
      "Epoch: [2][60/440] Elapsed 3m 27s (remain 21m 31s) Loss: 0.1012(0.1024) Grad: 151975.7812 LR: 0.00004842 \n",
      "Epoch: [2][80/440] Elapsed 4m 47s (remain 21m 15s) Loss: 0.0932(0.1043) Grad: 181441.8750 LR: 0.00004829 \n",
      "Epoch: [2][100/440] Elapsed 5m 49s (remain 19m 32s) Loss: 0.0906(0.1030) Grad: 117205.2266 LR: 0.00004816 \n",
      "Epoch: [2][120/440] Elapsed 6m 56s (remain 18m 18s) Loss: 0.1155(0.1033) Grad: 226675.9844 LR: 0.00004802 \n",
      "Epoch: [2][140/440] Elapsed 8m 3s (remain 17m 4s) Loss: 0.1311(0.1054) Grad: 210332.2656 LR: 0.00004788 \n",
      "Epoch: [2][160/440] Elapsed 9m 13s (remain 15m 59s) Loss: 0.1216(0.1048) Grad: 186858.3594 LR: 0.00004773 \n",
      "Epoch: [2][180/440] Elapsed 10m 41s (remain 15m 18s) Loss: 0.1045(0.1046) Grad: 318276.6875 LR: 0.00004758 \n",
      "Epoch: [2][200/440] Elapsed 11m 50s (remain 14m 4s) Loss: 0.1155(0.1041) Grad: 212847.8125 LR: 0.00004743 \n",
      "Epoch: [2][220/440] Elapsed 13m 0s (remain 12m 53s) Loss: 0.1169(0.1040) Grad: 45810.7500 LR: 0.00004727 \n",
      "Epoch: [2][240/440] Elapsed 14m 17s (remain 11m 47s) Loss: 0.1869(0.1044) Grad: 88524.0781 LR: 0.00004710 \n",
      "Epoch: [2][260/440] Elapsed 15m 26s (remain 10m 35s) Loss: 0.1044(0.1053) Grad: 53144.5625 LR: 0.00004693 \n",
      "Epoch: [2][280/440] Elapsed 16m 44s (remain 9m 28s) Loss: 0.1118(0.1048) Grad: 49527.3086 LR: 0.00004676 \n",
      "Epoch: [2][300/440] Elapsed 17m 43s (remain 8m 11s) Loss: 0.0890(0.1047) Grad: 68902.3203 LR: 0.00004658 \n",
      "Epoch: [2][320/440] Elapsed 18m 57s (remain 7m 1s) Loss: 0.1162(0.1049) Grad: 41278.4453 LR: 0.00004640 \n",
      "Epoch: [2][340/440] Elapsed 20m 6s (remain 5m 50s) Loss: 0.1545(0.1053) Grad: 125705.0156 LR: 0.00004621 \n",
      "Epoch: [2][360/440] Elapsed 21m 14s (remain 4m 38s) Loss: 0.1492(0.1060) Grad: 83489.3125 LR: 0.00004602 \n",
      "Epoch: [2][380/440] Elapsed 22m 20s (remain 3m 27s) Loss: 0.1041(0.1062) Grad: 82223.5938 LR: 0.00004583 \n",
      "Epoch: [2][400/440] Elapsed 23m 26s (remain 2m 16s) Loss: 0.1705(0.1066) Grad: 136118.3281 LR: 0.00004563 \n",
      "Epoch: [2][420/440] Elapsed 24m 34s (remain 1m 6s) Loss: 0.1181(0.1074) Grad: 45959.9688 LR: 0.00004542 \n",
      "Epoch: [2][439/440] Elapsed 25m 50s (remain 0m 0s) Loss: 0.0791(0.1072) Grad: 146866.1406 LR: 0.00004523 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 0m 54s) Loss: 0.1165(0.1165) \n",
      "EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1292(0.1267) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.1072  avg_val_loss: 0.1258  time: 1602s\n",
      "Epoch 2 - Score: 0.5034  Scores: [0.5147232865918544, 0.4913297159422431, 0.4580524196097426, 0.4784918609070734, 0.5725356097299256, 0.5055356041902628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1029(0.1258) \n",
      "Epoch: [3][0/440] Elapsed 0m 3s (remain 29m 15s) Loss: 0.0902(0.0902) Grad: 200197.7031 LR: 0.00004521 \n",
      "Epoch: [3][20/440] Elapsed 1m 26s (remain 28m 48s) Loss: 0.1287(0.1018) Grad: 198174.3281 LR: 0.00004500 \n",
      "Epoch: [3][40/440] Elapsed 2m 35s (remain 25m 12s) Loss: 0.1001(0.1007) Grad: 270166.0938 LR: 0.00004479 \n",
      "Epoch: [3][60/440] Elapsed 3m 42s (remain 23m 2s) Loss: 0.0589(0.0978) Grad: 121871.4531 LR: 0.00004457 \n",
      "Epoch: [3][80/440] Elapsed 4m 52s (remain 21m 37s) Loss: 0.0768(0.0967) Grad: 241294.7656 LR: 0.00004434 \n",
      "Epoch: [3][100/440] Elapsed 6m 8s (remain 20m 36s) Loss: 0.0579(0.0963) Grad: 151912.2812 LR: 0.00004411 \n",
      "Epoch: [3][120/440] Elapsed 7m 10s (remain 18m 54s) Loss: 0.0974(0.0954) Grad: 79820.9219 LR: 0.00004388 \n",
      "Epoch: [3][140/440] Elapsed 8m 30s (remain 18m 2s) Loss: 0.1350(0.0952) Grad: 143705.2812 LR: 0.00004365 \n",
      "Epoch: [3][160/440] Elapsed 9m 55s (remain 17m 11s) Loss: 0.0837(0.0954) Grad: 92739.2969 LR: 0.00004341 \n",
      "Epoch: [3][180/440] Elapsed 11m 9s (remain 15m 58s) Loss: 0.0659(0.0955) Grad: 114680.0703 LR: 0.00004316 \n",
      "Epoch: [3][200/440] Elapsed 12m 5s (remain 14m 23s) Loss: 0.1077(0.0952) Grad: 209408.3750 LR: 0.00004292 \n",
      "Epoch: [3][220/440] Elapsed 13m 6s (remain 12m 59s) Loss: 0.0674(0.0950) Grad: 126773.8203 LR: 0.00004267 \n",
      "Epoch: [3][240/440] Elapsed 14m 19s (remain 11m 50s) Loss: 0.0976(0.0950) Grad: 137017.2031 LR: 0.00004241 \n",
      "Epoch: [3][260/440] Elapsed 15m 28s (remain 10m 37s) Loss: 0.0949(0.0950) Grad: 214518.4844 LR: 0.00004215 \n",
      "Epoch: [3][280/440] Elapsed 16m 48s (remain 9m 30s) Loss: 0.1135(0.0953) Grad: 135599.1562 LR: 0.00004189 \n",
      "Epoch: [3][300/440] Elapsed 18m 9s (remain 8m 22s) Loss: 0.0891(0.0951) Grad: 94522.5312 LR: 0.00004163 \n",
      "Epoch: [3][320/440] Elapsed 19m 13s (remain 7m 7s) Loss: 0.0647(0.0952) Grad: 68207.4766 LR: 0.00004136 \n",
      "Epoch: [3][340/440] Elapsed 20m 25s (remain 5m 55s) Loss: 0.1225(0.0955) Grad: 86082.1406 LR: 0.00004109 \n",
      "Epoch: [3][360/440] Elapsed 21m 32s (remain 4m 42s) Loss: 0.1317(0.0956) Grad: 127631.2422 LR: 0.00004081 \n",
      "Epoch: [3][380/440] Elapsed 22m 33s (remain 3m 29s) Loss: 0.1007(0.0959) Grad: 117203.6641 LR: 0.00004053 \n",
      "Epoch: [3][400/440] Elapsed 23m 40s (remain 2m 18s) Loss: 0.0955(0.0960) Grad: 92460.5469 LR: 0.00004025 \n",
      "Epoch: [3][420/440] Elapsed 25m 3s (remain 1m 7s) Loss: 0.1511(0.0967) Grad: 49275.2891 LR: 0.00003997 \n",
      "Epoch: [3][439/440] Elapsed 25m 56s (remain 0m 0s) Loss: 0.1051(0.0970) Grad: 95181.6094 LR: 0.00003969 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 0m 59s) Loss: 0.1248(0.1248) \n",
      "EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1105(0.1168) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0970  avg_val_loss: 0.1170  time: 1609s\n",
      "Epoch 3 - Score: 0.4851  Scores: [0.5004429235179227, 0.4660150503626987, 0.43343136315188274, 0.47472323922538334, 0.508561447695547, 0.5272851797019898]\n",
      "Epoch 3 - Save Best Score: 0.4851 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0787(0.1170) \n",
      "Epoch: [4][0/440] Elapsed 0m 4s (remain 34m 29s) Loss: 0.0826(0.0826) Grad: 112453.2891 LR: 0.00003968 \n",
      "Epoch: [4][20/440] Elapsed 1m 23s (remain 27m 53s) Loss: 0.0843(0.0884) Grad: 352638.7188 LR: 0.00003939 \n",
      "Epoch: [4][40/440] Elapsed 2m 25s (remain 23m 37s) Loss: 0.0740(0.0894) Grad: 151669.7344 LR: 0.00003910 \n",
      "Epoch: [4][60/440] Elapsed 3m 44s (remain 23m 17s) Loss: 0.0639(0.0867) Grad: 118498.6562 LR: 0.00003880 \n",
      "Epoch: [4][80/440] Elapsed 5m 10s (remain 22m 58s) Loss: 0.0628(0.0846) Grad: 254405.7031 LR: 0.00003850 \n",
      "Epoch: [4][100/440] Elapsed 6m 45s (remain 22m 40s) Loss: 0.0732(0.0839) Grad: 137016.9375 LR: 0.00003820 \n",
      "Epoch: [4][120/440] Elapsed 7m 45s (remain 20m 27s) Loss: 0.0895(0.0845) Grad: 109383.9609 LR: 0.00003789 \n",
      "Epoch: [4][140/440] Elapsed 9m 6s (remain 19m 19s) Loss: 0.0883(0.0859) Grad: 122874.7891 LR: 0.00003759 \n",
      "Epoch: [4][160/440] Elapsed 10m 9s (remain 17m 35s) Loss: 0.0908(0.0868) Grad: 175935.0156 LR: 0.00003728 \n",
      "Epoch: [4][180/440] Elapsed 11m 12s (remain 16m 2s) Loss: 0.0764(0.0863) Grad: 79253.0938 LR: 0.00003697 \n",
      "Epoch: [4][200/440] Elapsed 12m 15s (remain 14m 34s) Loss: 0.1023(0.0852) Grad: 100336.8750 LR: 0.00003665 \n",
      "Epoch: [4][220/440] Elapsed 13m 30s (remain 13m 23s) Loss: 0.0754(0.0856) Grad: 61400.9805 LR: 0.00003633 \n",
      "Epoch: [4][240/440] Elapsed 14m 45s (remain 12m 11s) Loss: 0.0727(0.0853) Grad: 120540.6016 LR: 0.00003601 \n",
      "Epoch: [4][260/440] Elapsed 15m 46s (remain 10m 48s) Loss: 0.0726(0.0851) Grad: 68392.5938 LR: 0.00003569 \n",
      "Epoch: [4][280/440] Elapsed 16m 59s (remain 9m 36s) Loss: 0.0804(0.0848) Grad: 134641.1094 LR: 0.00003537 \n",
      "Epoch: [4][300/440] Elapsed 18m 3s (remain 8m 20s) Loss: 0.0814(0.0846) Grad: 174593.5312 LR: 0.00003504 \n",
      "Epoch: [4][320/440] Elapsed 19m 26s (remain 7m 12s) Loss: 0.0645(0.0849) Grad: 195140.9844 LR: 0.00003472 \n",
      "Epoch: [4][340/440] Elapsed 20m 25s (remain 5m 55s) Loss: 0.0962(0.0853) Grad: 129130.3828 LR: 0.00003439 \n",
      "Epoch: [4][360/440] Elapsed 21m 34s (remain 4m 43s) Loss: 0.0698(0.0851) Grad: 71498.5312 LR: 0.00003405 \n",
      "Epoch: [4][380/440] Elapsed 22m 41s (remain 3m 30s) Loss: 0.0808(0.0855) Grad: 126500.3203 LR: 0.00003372 \n",
      "Epoch: [4][400/440] Elapsed 23m 36s (remain 2m 17s) Loss: 0.0730(0.0851) Grad: 101717.6484 LR: 0.00003338 \n",
      "Epoch: [4][420/440] Elapsed 24m 39s (remain 1m 6s) Loss: 0.0945(0.0853) Grad: 126306.1562 LR: 0.00003305 \n",
      "Epoch: [4][439/440] Elapsed 25m 44s (remain 0m 0s) Loss: 0.1286(0.0852) Grad: 155625.2812 LR: 0.00003273 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 0m 53s) Loss: 0.1021(0.1021) \n",
      "EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1061(0.1090) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0852  avg_val_loss: 0.1087  time: 1596s\n",
      "Epoch 4 - Score: 0.4678  Scores: [0.5123521361764922, 0.4521896912123344, 0.4378181192704535, 0.4545032789643308, 0.47458204257259506, 0.47509480488548944]\n",
      "Epoch 4 - Save Best Score: 0.4678 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0867(0.1087) \n",
      "Epoch: [5][0/440] Elapsed 0m 7s (remain 52m 28s) Loss: 0.0839(0.0839) Grad: 106244.8203 LR: 0.00003271 \n",
      "Epoch: [5][20/440] Elapsed 1m 15s (remain 25m 15s) Loss: 0.0794(0.0709) Grad: 202476.9688 LR: 0.00003237 \n",
      "Epoch: [5][40/440] Elapsed 2m 30s (remain 24m 20s) Loss: 0.0741(0.0728) Grad: 136727.7188 LR: 0.00003203 \n",
      "Epoch: [5][60/440] Elapsed 3m 31s (remain 21m 56s) Loss: 0.0889(0.0706) Grad: 108038.3984 LR: 0.00003168 \n",
      "Epoch: [5][80/440] Elapsed 4m 50s (remain 21m 26s) Loss: 0.0755(0.0700) Grad: 104546.0625 LR: 0.00003134 \n",
      "Epoch: [5][100/440] Elapsed 6m 7s (remain 20m 33s) Loss: 0.1032(0.0696) Grad: 216607.2656 LR: 0.00003099 \n",
      "Epoch: [5][120/440] Elapsed 7m 14s (remain 19m 6s) Loss: 0.0770(0.0705) Grad: 108935.2656 LR: 0.00003065 \n",
      "Epoch: [5][140/440] Elapsed 8m 20s (remain 17m 41s) Loss: 0.0459(0.0701) Grad: 88407.4297 LR: 0.00003030 \n",
      "Epoch: [5][160/440] Elapsed 9m 34s (remain 16m 34s) Loss: 0.0961(0.0708) Grad: 183286.1875 LR: 0.00002995 \n",
      "Epoch: [5][180/440] Elapsed 10m 45s (remain 15m 23s) Loss: 0.0834(0.0715) Grad: 139819.8438 LR: 0.00002960 \n",
      "Epoch: [5][200/440] Elapsed 11m 51s (remain 14m 5s) Loss: 0.0778(0.0719) Grad: 111055.9688 LR: 0.00002925 \n",
      "Epoch: [5][220/440] Elapsed 12m 56s (remain 12m 49s) Loss: 0.0990(0.0716) Grad: 188513.5000 LR: 0.00002889 \n",
      "Epoch: [5][240/440] Elapsed 14m 12s (remain 11m 43s) Loss: 0.0596(0.0713) Grad: 180669.0469 LR: 0.00002854 \n",
      "Epoch: [5][260/440] Elapsed 15m 19s (remain 10m 30s) Loss: 0.0486(0.0711) Grad: 81052.6562 LR: 0.00002819 \n",
      "Epoch: [5][280/440] Elapsed 16m 40s (remain 9m 26s) Loss: 0.0654(0.0717) Grad: 282661.8750 LR: 0.00002783 \n",
      "Epoch: [5][300/440] Elapsed 17m 47s (remain 8m 13s) Loss: 0.1140(0.0717) Grad: 213197.5469 LR: 0.00002748 \n",
      "Epoch: [5][320/440] Elapsed 18m 59s (remain 7m 2s) Loss: 0.0672(0.0713) Grad: 120104.6172 LR: 0.00002712 \n",
      "Epoch: [5][340/440] Elapsed 20m 5s (remain 5m 50s) Loss: 0.0667(0.0712) Grad: 99597.5469 LR: 0.00002677 \n",
      "Epoch: [5][360/440] Elapsed 21m 16s (remain 4m 39s) Loss: 0.0946(0.0716) Grad: 167744.8594 LR: 0.00002641 \n",
      "Epoch: [5][380/440] Elapsed 22m 12s (remain 3m 26s) Loss: 0.0654(0.0713) Grad: 169232.5000 LR: 0.00002605 \n",
      "Epoch: [5][400/440] Elapsed 23m 26s (remain 2m 16s) Loss: 0.0456(0.0713) Grad: 95097.1797 LR: 0.00002570 \n",
      "Epoch: [5][420/440] Elapsed 24m 35s (remain 1m 6s) Loss: 0.0681(0.0714) Grad: 112057.2578 LR: 0.00002534 \n",
      "Epoch: [5][439/440] Elapsed 25m 50s (remain 0m 0s) Loss: 0.0635(0.0714) Grad: 131507.2656 LR: 0.00002500 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 0m 53s) Loss: 0.1150(0.1150) \n",
      "EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1181(0.1164) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.0714  avg_val_loss: 0.1177  time: 1602s\n",
      "Epoch 5 - Score: 0.4859  Scores: [0.5421805940010731, 0.4662993066328711, 0.4443467849653943, 0.46357267361828625, 0.5040775019338716, 0.49469871017607375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0883(0.1177) \n",
      "Epoch: [6][0/440] Elapsed 0m 6s (remain 47m 39s) Loss: 0.0917(0.0917) Grad: 442386.8750 LR: 0.00002498 \n",
      "Epoch: [6][20/440] Elapsed 1m 23s (remain 27m 41s) Loss: 0.0657(0.0660) Grad: 111982.5234 LR: 0.00002463 \n",
      "Epoch: [6][40/440] Elapsed 2m 32s (remain 24m 40s) Loss: 0.0707(0.0617) Grad: 254861.9688 LR: 0.00002427 \n",
      "Epoch: [6][60/440] Elapsed 3m 43s (remain 23m 5s) Loss: 0.0443(0.0608) Grad: 49484.4570 LR: 0.00002391 \n",
      "Epoch: [6][80/440] Elapsed 4m 43s (remain 20m 55s) Loss: 0.0462(0.0609) Grad: 175829.0000 LR: 0.00002355 \n",
      "Epoch: [6][100/440] Elapsed 5m 54s (remain 19m 51s) Loss: 0.0906(0.0635) Grad: 198658.3438 LR: 0.00002320 \n",
      "Epoch: [6][120/440] Elapsed 7m 5s (remain 18m 42s) Loss: 0.0566(0.0633) Grad: 218525.0625 LR: 0.00002284 \n",
      "Epoch: [6][140/440] Elapsed 8m 8s (remain 17m 16s) Loss: 0.0522(0.0625) Grad: 111764.6094 LR: 0.00002249 \n",
      "Epoch: [6][160/440] Elapsed 9m 13s (remain 15m 59s) Loss: 0.0521(0.0620) Grad: 84690.7031 LR: 0.00002213 \n",
      "Epoch: [6][180/440] Elapsed 10m 41s (remain 15m 18s) Loss: 0.0507(0.0618) Grad: 93629.0000 LR: 0.00002178 \n",
      "Epoch: [6][200/440] Elapsed 11m 43s (remain 13m 56s) Loss: 0.0707(0.0617) Grad: 146662.7344 LR: 0.00002142 \n",
      "Epoch: [6][220/440] Elapsed 13m 7s (remain 13m 0s) Loss: 0.0779(0.0616) Grad: 137739.4844 LR: 0.00002107 \n",
      "Epoch: [6][240/440] Elapsed 14m 17s (remain 11m 48s) Loss: 0.0514(0.0616) Grad: 155621.1094 LR: 0.00002072 \n",
      "Epoch: [6][260/440] Elapsed 15m 27s (remain 10m 35s) Loss: 0.0554(0.0609) Grad: 89296.5156 LR: 0.00002037 \n",
      "Epoch: [6][280/440] Elapsed 16m 34s (remain 9m 22s) Loss: 0.0503(0.0602) Grad: 93003.7031 LR: 0.00002002 \n",
      "Epoch: [6][300/440] Elapsed 17m 49s (remain 8m 13s) Loss: 0.0577(0.0604) Grad: 107322.7812 LR: 0.00001967 \n",
      "Epoch: [6][320/440] Elapsed 18m 58s (remain 7m 2s) Loss: 0.0316(0.0601) Grad: 88001.9297 LR: 0.00001932 \n",
      "Epoch: [6][340/440] Elapsed 20m 10s (remain 5m 51s) Loss: 0.0738(0.0598) Grad: 73059.4844 LR: 0.00001897 \n",
      "Epoch: [6][360/440] Elapsed 21m 24s (remain 4m 41s) Loss: 0.0644(0.0598) Grad: 132839.7500 LR: 0.00001863 \n",
      "Epoch: [6][380/440] Elapsed 22m 38s (remain 3m 30s) Loss: 0.0599(0.0599) Grad: 94031.7266 LR: 0.00001828 \n",
      "Epoch: [6][400/440] Elapsed 23m 42s (remain 2m 18s) Loss: 0.0686(0.0596) Grad: 102943.3359 LR: 0.00001794 \n",
      "Epoch: [6][420/440] Elapsed 24m 48s (remain 1m 7s) Loss: 0.0620(0.0594) Grad: 230025.2344 LR: 0.00001760 \n",
      "Epoch: [6][439/440] Elapsed 25m 54s (remain 0m 0s) Loss: 0.0535(0.0594) Grad: 110718.0000 LR: 0.00001727 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 0m 53s) Loss: 0.1119(0.1119) \n",
      "EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1295(0.1186) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.0594  avg_val_loss: 0.1186  time: 1606s\n",
      "Epoch 6 - Score: 0.4885  Scores: [0.5421939734369357, 0.4740417187153399, 0.4369675934949415, 0.4694529235553944, 0.5070030535855489, 0.5011038841183127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1166(0.1186) \n",
      "Epoch: [7][0/440] Elapsed 0m 2s (remain 21m 49s) Loss: 0.0618(0.0618) Grad: 130974.2578 LR: 0.00001726 \n",
      "Epoch: [7][20/440] Elapsed 1m 16s (remain 25m 23s) Loss: 0.0400(0.0492) Grad: 79161.5312 LR: 0.00001692 \n",
      "Epoch: [7][40/440] Elapsed 2m 17s (remain 22m 18s) Loss: 0.0485(0.0492) Grad: 72518.5859 LR: 0.00001658 \n",
      "Epoch: [7][60/440] Elapsed 3m 39s (remain 22m 42s) Loss: 0.0532(0.0471) Grad: 112403.6172 LR: 0.00001625 \n",
      "Epoch: [7][80/440] Elapsed 4m 54s (remain 21m 46s) Loss: 0.0399(0.0474) Grad: 103071.8125 LR: 0.00001591 \n",
      "Epoch: [7][100/440] Elapsed 5m 57s (remain 19m 58s) Loss: 0.0544(0.0475) Grad: 306233.4375 LR: 0.00001558 \n",
      "Epoch: [7][120/440] Elapsed 7m 6s (remain 18m 45s) Loss: 0.0487(0.0480) Grad: 113251.4062 LR: 0.00001525 \n",
      "Epoch: [7][140/440] Elapsed 8m 10s (remain 17m 21s) Loss: 0.0428(0.0479) Grad: 124592.5859 LR: 0.00001492 \n",
      "Epoch: [7][160/440] Elapsed 9m 16s (remain 16m 4s) Loss: 0.0497(0.0483) Grad: 95337.2344 LR: 0.00001460 \n",
      "Epoch: [7][180/440] Elapsed 10m 16s (remain 14m 42s) Loss: 0.0559(0.0484) Grad: 80120.5625 LR: 0.00001427 \n",
      "Epoch: [7][200/440] Elapsed 11m 44s (remain 13m 57s) Loss: 0.0401(0.0485) Grad: 353358.4062 LR: 0.00001395 \n",
      "Epoch: [7][220/440] Elapsed 12m 58s (remain 12m 51s) Loss: 0.0433(0.0483) Grad: 68140.0391 LR: 0.00001363 \n",
      "Epoch: [7][240/440] Elapsed 14m 1s (remain 11m 34s) Loss: 0.0391(0.0480) Grad: 103112.8672 LR: 0.00001332 \n",
      "Epoch: [7][260/440] Elapsed 15m 16s (remain 10m 28s) Loss: 0.0851(0.0484) Grad: 554634.1250 LR: 0.00001300 \n",
      "Epoch: [7][280/440] Elapsed 16m 33s (remain 9m 21s) Loss: 0.0470(0.0480) Grad: 90933.8516 LR: 0.00001269 \n",
      "Epoch: [7][300/440] Elapsed 17m 54s (remain 8m 15s) Loss: 0.0411(0.0482) Grad: 98222.9453 LR: 0.00001238 \n",
      "Epoch: [7][320/440] Elapsed 18m 54s (remain 7m 0s) Loss: 0.0423(0.0481) Grad: 94620.7891 LR: 0.00001207 \n",
      "Epoch: [7][340/440] Elapsed 19m 55s (remain 5m 47s) Loss: 0.0596(0.0481) Grad: 197467.0781 LR: 0.00001177 \n",
      "Epoch: [7][360/440] Elapsed 21m 7s (remain 4m 37s) Loss: 0.0528(0.0481) Grad: 107581.3359 LR: 0.00001147 \n",
      "Epoch: [7][380/440] Elapsed 22m 23s (remain 3m 27s) Loss: 0.0309(0.0480) Grad: 96052.1797 LR: 0.00001117 \n",
      "Epoch: [7][400/440] Elapsed 23m 28s (remain 2m 16s) Loss: 0.0675(0.0480) Grad: 134844.1875 LR: 0.00001087 \n",
      "Epoch: [7][420/440] Elapsed 24m 28s (remain 1m 6s) Loss: 0.0539(0.0480) Grad: 65148.0352 LR: 0.00001058 \n",
      "Epoch: [7][439/440] Elapsed 25m 49s (remain 0m 0s) Loss: 0.0360(0.0479) Grad: 106528.5156 LR: 0.00001031 \n",
      "EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1044(0.1044) \n",
      "EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1312(0.1168) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.0479  avg_val_loss: 0.1176  time: 1602s\n",
      "Epoch 7 - Score: 0.4871  Scores: [0.5226423394910589, 0.4688142976883629, 0.44874927164275896, 0.47791629297927957, 0.5158205230652946, 0.48876149642319483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1091(0.1176) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 0.4678  Scores: [0.5123521361764922, 0.4521896912123344, 0.4378181192704535, 0.4545032789643308, 0.47458204257259506, 0.47509480488548944]\n",
      "========== fold: 2 training ==========\n",
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/440] Elapsed 0m 7s (remain 54m 40s) Loss: 2.4303(2.4303) Grad: inf LR: 0.00005000 \n",
      "Epoch: [1][20/440] Elapsed 1m 21s (remain 27m 12s) Loss: 0.3809(1.1915) Grad: 229728.6562 LR: 0.00005000 \n",
      "Epoch: [1][40/440] Elapsed 2m 28s (remain 24m 9s) Loss: 0.3517(0.7347) Grad: 170127.8750 LR: 0.00004999 \n",
      "Epoch: [1][60/440] Elapsed 3m 51s (remain 23m 56s) Loss: 0.2488(0.5512) Grad: 159868.9219 LR: 0.00004998 \n",
      "Epoch: [1][80/440] Elapsed 4m 52s (remain 21m 34s) Loss: 0.1270(0.4504) Grad: 97422.8438 LR: 0.00004996 \n",
      "Epoch: [1][100/440] Elapsed 6m 19s (remain 21m 15s) Loss: 0.1498(0.3870) Grad: 116837.7891 LR: 0.00004994 \n",
      "Epoch: [1][120/440] Elapsed 7m 35s (remain 20m 1s) Loss: 0.1959(0.3448) Grad: 215351.0312 LR: 0.00004991 \n",
      "Epoch: [1][140/440] Elapsed 8m 49s (remain 18m 42s) Loss: 0.1490(0.3143) Grad: 143927.0938 LR: 0.00004987 \n",
      "Epoch: [1][160/440] Elapsed 9m 57s (remain 17m 15s) Loss: 0.1135(0.2932) Grad: 66896.3125 LR: 0.00004984 \n",
      "Epoch: [1][180/440] Elapsed 11m 4s (remain 15m 51s) Loss: 0.0892(0.2745) Grad: 47979.1758 LR: 0.00004979 \n",
      "Epoch: [1][200/440] Elapsed 12m 19s (remain 14m 39s) Loss: 0.0859(0.2579) Grad: 84796.2656 LR: 0.00004974 \n",
      "Epoch: [1][220/440] Elapsed 13m 24s (remain 13m 17s) Loss: 0.1419(0.2453) Grad: 207776.2500 LR: 0.00004969 \n",
      "Epoch: [1][240/440] Elapsed 14m 33s (remain 12m 1s) Loss: 0.1064(0.2352) Grad: 64206.6133 LR: 0.00004963 \n",
      "Epoch: [1][260/440] Elapsed 15m 42s (remain 10m 46s) Loss: 0.1508(0.2263) Grad: 150680.1094 LR: 0.00004957 \n",
      "Epoch: [1][280/440] Elapsed 16m 53s (remain 9m 33s) Loss: 0.1161(0.2186) Grad: 120937.4141 LR: 0.00004950 \n",
      "Epoch: [1][300/440] Elapsed 18m 1s (remain 8m 19s) Loss: 0.0937(0.2119) Grad: 55199.2656 LR: 0.00004942 \n",
      "Epoch: [1][320/440] Elapsed 19m 1s (remain 7m 3s) Loss: 0.0794(0.2062) Grad: 84644.3984 LR: 0.00004935 \n",
      "Epoch: [1][340/440] Elapsed 20m 2s (remain 5m 49s) Loss: 0.1426(0.2004) Grad: 73670.5625 LR: 0.00004926 \n",
      "Epoch: [1][360/440] Elapsed 21m 8s (remain 4m 37s) Loss: 0.1689(0.1963) Grad: 164419.6562 LR: 0.00004917 \n",
      "Epoch: [1][380/440] Elapsed 22m 37s (remain 3m 30s) Loss: 0.1659(0.1923) Grad: 116051.7656 LR: 0.00004908 \n",
      "Epoch: [1][400/440] Elapsed 23m 41s (remain 2m 18s) Loss: 0.1000(0.1887) Grad: 96645.2266 LR: 0.00004898 \n",
      "Epoch: [1][420/440] Elapsed 24m 54s (remain 1m 7s) Loss: 0.1187(0.1857) Grad: 106183.2891 LR: 0.00004888 \n",
      "Epoch: [1][439/440] Elapsed 26m 15s (remain 0m 0s) Loss: 0.1108(0.1829) Grad: 63031.2227 LR: 0.00004878 \n",
      "EVAL: [0/25] Elapsed 0m 3s (remain 1m 23s) Loss: 0.1387(0.1387) \n"
     ]
    }
   ],
   "source": [
    "if CFG.train:\n",
    "    output_log = pd.DataFrame()\n",
    "    oof_df = pd.DataFrame()\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    for fold in range(CFG.n_fold):\n",
    "        if fold in CFG.trn_fold:\n",
    "            best_train_loss, best_val_loss, _oof_df, df_epoch_scores = train_loop(CFG.df_train, fold)\n",
    "            train_loss_list.append(best_train_loss)\n",
    "            val_loss_list.append(best_val_loss)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            oof_df.to_pickle(CFG.OUTPUT_DIR+f'oof_df_fold{fold}.pkl', protocol = 4)\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "\n",
    "            df_epoch_scores['file'] = f\"{model_name}-{CFG.file_name}\"\n",
    "            df_epoch_scores['model'] = CFG.model\n",
    "            df_epoch_scores['cv_seed'] = CFG.cv_seed\n",
    "            df_epoch_scores['seed'] = CFG.seed\n",
    "            df_epoch_scores['fold'] = fold\n",
    "            df_epoch_scores = df_epoch_scores[['file', 'model', 'cv_seed', 'seed', 'fold', 'epoch', 'MCRMSE', 'train_loss', 'val_loss'] + CFG.target_cols]\n",
    "\n",
    "            _output_log = get_result(_oof_df, fold, best_train_loss, best_val_loss)\n",
    "            output_log = pd.concat([output_log, df_epoch_scores, _output_log])\n",
    "\n",
    "    oof_df = oof_df.reset_index(drop=True)\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    _output_log = get_result(oof_df, 'OOF', np.mean(train_loss_list), np.mean(val_loss_list))\n",
    "    output_log = pd.concat([output_log, _output_log])\n",
    "    output_log.to_csv(CFG.OUTPUT_DIR+f\"{model_name}-{CFG.file_name}.csv\", index=False)\n",
    "    oof_df.to_pickle(CFG.OUTPUT_DIR+'oof_df.pkl', protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea28cda-a285-4c5e-ac46-84c24d1ffe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.OUTPUT_DIR = \"/home/jupyter/output/ex/deberta-v3-base/018/202211261205/\"\n",
    "\n",
    "if \"/\" in CFG.model:\n",
    "    model_name = CFG.model.split(\"/\")[1]\n",
    "else:\n",
    "    model_name = CFG.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b18dd8c-0d69-451f-98cb-c2c1abba3861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file microsoft-deberta-v3-base_fold6_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:19<00:00, 38.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold6_best.pth (704MB)\n",
      "Starting upload for file oof_df_fold3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 3.69M/3.69M [00:02<00:00, 1.44MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold3.pkl (4MB)\n",
      "Starting upload for file oof_df_fold6.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 6.41M/6.41M [00:02<00:00, 2.85MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold6.pkl (6MB)\n",
      "Starting upload for file oof_df_fold1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1.86M/1.86M [00:02<00:00, 852kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold1.pkl (2MB)\n",
      "Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n",
      "Starting upload for file oof_df_fold4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 4.59M/4.59M [00:02<00:00, 1.87MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold4.pkl (5MB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold7_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:21<00:00, 34.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold7_best.pth (704MB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold5_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:20<00:00, 36.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold5_best.pth (704MB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:16<00:00, 44.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold0_best.pth (704MB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold4_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:20<00:00, 36.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold4_best.pth (704MB)\n",
      "Starting upload for file oof_df_fold0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 952k/952k [00:01<00:00, 522kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold0.pkl (952KB)\n",
      "Starting upload for file oof_df_fold5.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5.49M/5.49M [00:02<00:00, 2.03MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold5.pkl (5MB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold1_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:20<00:00, 35.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold1_best.pth (704MB)\n",
      "Starting upload for file oof_df_fold7.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 7.27M/7.27M [00:02<00:00, 2.97MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold7.pkl (7MB)\n",
      "Starting upload for file train.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 22.4k/22.4k [00:02<00:00, 10.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: train.log (22KB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold3_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:21<00:00, 34.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold3_best.pth (704MB)\n",
      "Starting upload for file oof_df_fold2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2.76M/2.76M [00:02<00:00, 1.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_df_fold2.pkl (3MB)\n",
      "Starting upload for file microsoft-deberta-v3-base_fold2_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 704M/704M [00:17<00:00, 42.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: microsoft-deberta-v3-base_fold2_best.pth (704MB)\n"
     ]
    }
   ],
   "source": [
    "if CFG.TO_KAGGLE:\n",
    "    UPLOAD_DIR = CFG.OUTPUT_DIR\n",
    "    EX_NO = f\"{model_name}{CFG.file_name}\" # folderpath\n",
    "    USERID = 'your_id'\n",
    "\n",
    "\n",
    "    def dataset_upload():\n",
    "        import json\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "        id = f'{USERID}/{EX_NO}'\n",
    "\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata['id'] = id\n",
    "        dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "        dataset_metadata['title'] = f'{EX_NO}'\n",
    "\n",
    "        with open(UPLOAD_DIR +'dataset-metadata.json', 'w') as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "\n",
    "        # \n",
    "        if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
    "            api.dataset_create_new(folder=UPLOAD_DIR,\n",
    "                                   convert_to_csv=False,\n",
    "                                   dir_mode='skip')\n",
    "            \n",
    "            \n",
    "            #  #\n",
    "            # if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
    "            #     remove_files = glob.glob(OUTPUT_DIR+\"*\")\n",
    "            #     remove_files.remove(OUTPUT_DIR+\"oof_df.pkl\")\n",
    "            #     for file in remove_files:\n",
    "            #         os.remove(file)\n",
    "            #     print(\"folder upload\")\n",
    "            #                 #api\n",
    "            #     f = open(f'{model_name}_api_command.txt', 'a')\n",
    "            #     api_command = f\"!kaggle datasets download -d hiroki8383/{EX_NO}\\n\"\n",
    "            #     f.write(api_command)\n",
    "            #     f.close()\n",
    "            # else:\n",
    "            #     print(\"folder not upload\")\n",
    "            \n",
    "            \n",
    "        # )\n",
    "        else:\n",
    "            print(\"this folder exsits\")\n",
    "            # api.dataset_create_version(folder=UPLOAD_DIR,\n",
    "            #                            version_notes='update',\n",
    "            #                            convert_to_csv=False,\n",
    "            #                            delete_old_versions=False,\n",
    "            #                            dir_mode='zip')\n",
    "    dataset_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee1487-e2fd-4468-989f-d3f82f902b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8967095-b6b6-4383-8ad6-9351e6be1b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.347487,
   "end_time": "2022-11-11T06:13:06.130510",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-11T06:12:26.783023",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1091895a476f464b835f26c80d699e9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_edd8b9d28b124eab9d9f29e1ea8f47dc",
       "placeholder": "",
       "style": "IPY_MODEL_788e17e7d5224da7accd4f6c07d1d90c",
       "value": "Downloading: 100%"
      }
     },
     "10cc4a6ea4634108b00f3a2fd5a63e5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "166c33eda8dc46cda76f50053888af13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9d040c6671ae4c60b021f4e8a0c9451f",
       "placeholder": "",
       "style": "IPY_MODEL_8e08f1513e4b4bf1bcb7f9e470339b5d",
       "value": " 579/579 [00:00&lt;00:00, 21.5kB/s]"
      }
     },
     "1c0aac6154d1486a9526b52ec010b8da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f4f92a14bcd45aa9d79affc714d28aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "33cdd914b8794dc486baf7fd85041b13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a79897b240e4ac2a78979e61a57bdf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bf5baa2492745c1aee85d9ca7202f32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5c3d96ee6d7a437fbcfe2c2d5fe4ae9b",
       "placeholder": "",
       "style": "IPY_MODEL_f03efc83b5e24f459769375928439da2",
       "value": "100%"
      }
     },
     "3c7c0fe937d04736950f493bdc38d11d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "42e2b232cd104924b1ce885b778b4129": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4a4f4e661aeb4790b83b89eb46523420": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4adec9f561a544e68ee7d1edb427fac4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5283e532caaa48b18e0ce84e695a9640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b944f0c1790404e8a549510cb517aa4",
       "max": 579,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fa5a0cdc52fb4cca951a47d42f19981b",
       "value": 579
      }
     },
     "550a7832f1744743aba094ee34417675": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33cdd914b8794dc486baf7fd85041b13",
       "max": 2464616,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a879a3b4a0624ba88b1e1d51ebb58077",
       "value": 2464616
      }
     },
     "58f3913d9ad04745a7c42b92dceb1985": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c3d96ee6d7a437fbcfe2c2d5fe4ae9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62636e6b8ca446ea91e8663aaa41a841": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a79897b240e4ac2a78979e61a57bdf7",
       "placeholder": "",
       "style": "IPY_MODEL_42e2b232cd104924b1ce885b778b4129",
       "value": "Downloading: 100%"
      }
     },
     "65586b8daceb424d94e2bdd9ec28776e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "788e17e7d5224da7accd4f6c07d1d90c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a5a06b92984427b9f2f7343c65f0878": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83de2ae5aab944df9b04596709c32927": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_97681a158e734e9795e982548ae9c80a",
       "max": 52,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f4a09cc8d22e4c8daa73e28a95119eab",
       "value": 52
      }
     },
     "8e08f1513e4b4bf1bcb7f9e470339b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "92c6635a3f3e4413bf5e7382bb03594b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "97681a158e734e9795e982548ae9c80a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b944f0c1790404e8a549510cb517aa4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d040c6671ae4c60b021f4e8a0c9451f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d0d9211a766488e906cc8530ec0ec8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a5a06b92984427b9f2f7343c65f0878",
       "placeholder": "",
       "style": "IPY_MODEL_accb9da32d79417980b3b9bd128b006c",
       "value": "Downloading: 100%"
      }
     },
     "a879a3b4a0624ba88b1e1d51ebb58077": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "accb9da32d79417980b3b9bd128b006c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b70bb3c4a28c4dfc99605ff0939222bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9d0d9211a766488e906cc8530ec0ec8d",
        "IPY_MODEL_5283e532caaa48b18e0ce84e695a9640",
        "IPY_MODEL_166c33eda8dc46cda76f50053888af13"
       ],
       "layout": "IPY_MODEL_4a4f4e661aeb4790b83b89eb46523420"
      }
     },
     "c42c40480c6a4698ac54414630f8f1ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db137b7027724ef19419dc4690c182fe",
       "placeholder": "",
       "style": "IPY_MODEL_3c7c0fe937d04736950f493bdc38d11d",
       "value": " 2.35M/2.35M [00:00&lt;00:00, 3.28MB/s]"
      }
     },
     "cc24ee6f778e4b93bcde025d965c90fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10cc4a6ea4634108b00f3a2fd5a63e5c",
       "placeholder": "",
       "style": "IPY_MODEL_e31e9e506f344931a5729455c9a99953",
       "value": " 3911/3911 [00:06&lt;00:00, 703.85it/s]"
      }
     },
     "cd0c10df137145649fd408daf78c011f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62636e6b8ca446ea91e8663aaa41a841",
        "IPY_MODEL_83de2ae5aab944df9b04596709c32927",
        "IPY_MODEL_fb44d082374f4a179e6788f657a97aad"
       ],
       "layout": "IPY_MODEL_1c0aac6154d1486a9526b52ec010b8da"
      }
     },
     "d3713a7be7e2453398500ccd1d1bbfec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8474a2abd2642c6a330952df1d04600": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1091895a476f464b835f26c80d699e9d",
        "IPY_MODEL_550a7832f1744743aba094ee34417675",
        "IPY_MODEL_c42c40480c6a4698ac54414630f8f1ef"
       ],
       "layout": "IPY_MODEL_4adec9f561a544e68ee7d1edb427fac4"
      }
     },
     "d94c00f20aaf4b368f11154d86931b0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3bf5baa2492745c1aee85d9ca7202f32",
        "IPY_MODEL_dd25ec2004404f3e82e7541528157eaf",
        "IPY_MODEL_cc24ee6f778e4b93bcde025d965c90fa"
       ],
       "layout": "IPY_MODEL_65586b8daceb424d94e2bdd9ec28776e"
      }
     },
     "db137b7027724ef19419dc4690c182fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd25ec2004404f3e82e7541528157eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_58f3913d9ad04745a7c42b92dceb1985",
       "max": 3911,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92c6635a3f3e4413bf5e7382bb03594b",
       "value": 3911
      }
     },
     "e31e9e506f344931a5729455c9a99953": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "edd8b9d28b124eab9d9f29e1ea8f47dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f03efc83b5e24f459769375928439da2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f4a09cc8d22e4c8daa73e28a95119eab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fa5a0cdc52fb4cca951a47d42f19981b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fb44d082374f4a179e6788f657a97aad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3713a7be7e2453398500ccd1d1bbfec",
       "placeholder": "",
       "style": "IPY_MODEL_2f4f92a14bcd45aa9d79affc714d28aa",
       "value": " 52.0/52.0 [00:00&lt;00:00, 1.72kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
