{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfc66b5-c36f-4e45-b7ae-550b85017f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb = True\n",
    "    DEBUG = False\n",
    "    DL = False\n",
    "    file_name = \"002\"\n",
    "    model=\"mpnet-base\"\n",
    "    n_fold=4\n",
    "    trn_fold=[0, 1, 2, 3]\n",
    "    model_config_path = f\"/home/jupyter/models/{model}\"\n",
    "    model_bin_path = f\"/home/jupyter/models/{model}\"\n",
    "    competition='FB3'\n",
    "    apex=True\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    gradient_checkpointing=False\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=6\n",
    "    encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=8\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    train=True\n",
    "    \n",
    "if CFG.DEBUG:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d03f25-2190-4708-b4b2-ed92b3870d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# library\n",
    "# ========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import MPNetModel, MPNetTokenizer\n",
    "import logging\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "# ==================\n",
    "# Constant\n",
    "# ==================\n",
    "ex = \"292\"\n",
    "\n",
    "TRAIN_PATH = '/home/jupyter/feedback-prize-english-language-learning/train.csv'\n",
    "\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# datetime\n",
    "# ====================================================\n",
    "t_delta = datetime.timedelta(hours=9)\n",
    "JST = datetime.timezone(t_delta, 'JST')\n",
    "now = datetime.datetime.now(JST)\n",
    "date = now.strftime('%Y%m%d')\n",
    "date2 = now.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# file_path\n",
    "# ====================================================\n",
    "if \"/\" in CFG.model:\n",
    "    model_name = CFG.model.split(\"/\")[1]\n",
    "else:\n",
    "    model_name = CFG.model\n",
    "\n",
    "path =\"/home/jupyter/feedback-prize-english-language-learning/\"\n",
    "if CFG.DEBUG:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/DEBUG/{model_name}/{CFG.file_name}/{date2}/'\n",
    "else:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/{model_name}/{CFG.file_name}/{date2}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "\n",
    "MODEL_PATH_BASE = OUTPUT_DIR+f\"ex{ex}\"\n",
    "OOF_SAVE_PATH = OUTPUT_DIR+f\"ex{ex}_oof.npy\"\n",
    "LOGGER_PATH = OUTPUT_DIR+f\"/ex{ex}.txt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# ===============\n",
    "# Settings\n",
    "# ===============\n",
    "SEED = 0\n",
    "num_workers = 4\n",
    "BATCH_SIZE = 8\n",
    "n_epochs = 5\n",
    "es_patience = 10\n",
    "max_len = 256\n",
    "weight_decay = 0.1\n",
    "lr = 3e-5\n",
    "num_warmup_steps_rate = 0\n",
    "eval_steps = 40\n",
    "\n",
    "MODEL_PATH = \"/home/jupyter/models/mpnet-base/\"\n",
    "tokenizer = MPNetTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347e2b92-b39b-4b06-8533-1fe1f180eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 07:26:10,628 - INFO - logger set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CommonLitDataset(Dataset):\n",
    "    def __init__(self, excerpt, tokenizer, max_len, target=None):\n",
    "        self.excerpt = excerpt\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.excerpt[item])\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        if self.target is not None:\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "                \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                \"target\": torch.tensor(self.target[item], dtype=torch.float32)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "                \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "\n",
    "class mpnet_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mpnet_model, self).__init__()\n",
    "        self.mpnet = MPNetModel.from_pretrained(\n",
    "            MODEL_PATH,\n",
    "            hidden_dropout_prob=0,\n",
    "            attention_probs_dropout_prob=0\n",
    "        )\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.2)\n",
    "        self.ln = nn.LayerNorm(768)\n",
    "        self.out = nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        # pooler\n",
    "        emb = self.mpnet(ids, attention_mask=mask, token_type_ids=token_type_ids)[\n",
    "            \"last_hidden_state\"]\n",
    "        emb = torch.mean(emb, axis=1)\n",
    "        output = self.ln(emb)\n",
    "        # output = self.dropout(output)\n",
    "        output = self.out(output)\n",
    "        return output, emb\n",
    "\n",
    "\n",
    "def calc_loss(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def setup_logger(out_file=None, stderr=True, stderr_level=logging.INFO, file_level=logging.DEBUG):\n",
    "    LOGGER.handlers = []\n",
    "    LOGGER.setLevel(min(stderr_level, file_level))\n",
    "\n",
    "    if stderr:\n",
    "        handler = logging.StreamHandler(sys.stderr)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(stderr_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        handler = logging.FileHandler(out_file)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(file_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    LOGGER.info(\"logger set up\")\n",
    "    return LOGGER\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "setup_logger(out_file=LOGGER_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cafeed9-d781-48a7-a40a-053d4664b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Main\n",
    "# ================================\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "y = train[CFG.target_cols]\n",
    "#fold_df = pd.read_csv(FOLD_PATH)\n",
    "fold_array = np.load(\"/home/jupyter/output/fold/4fold.npy\")\n",
    "\n",
    "if CFG.DEBUG:\n",
    "    train = pd.read_csv(TRAIN_PATH,nrows=100)\n",
    "    y = train[CFG.target_cols]\n",
    "    #fold_df = pd.read_csv(FOLD_PATH)\n",
    "    fold_array = np.load(\"/home/jupyter/output/fold/4fold.npy\")[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e4c550-24d2-4096-9016-170967ba729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311b0f48-07cc-4811-bb63-5d531c3fbb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0% 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:26:33,996 - INFO - 0,0:0,val_loss:1.567530895151743,val_rmse:2.2084815796330974\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:27:17,528 - INFO - 0,0:40,val_loss:0.21617305560446368,val_rmse:0.6629622877971874\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:27:51,902 - INFO - 0,0:80,val_loss:0.2250841147440478,val_rmse:0.6562950915428752\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:28:26,191 - INFO - 0,0:120,val_loss:0.21448166332230334,val_rmse:0.667264420968158\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:28:56,346 - INFO - 0,0:160,val_loss:0.20635265127066674,val_rmse:0.6443466390315984\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:29:30,155 - INFO - 0,0:200,val_loss:0.21058166105815065,val_rmse:0.6424162115720078\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:30:03,873 - INFO - 0,0:240,val_loss:0.2116548581336572,val_rmse:0.6481792881827145\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:30:33,770 - INFO - 0,0:280,val_loss:0.20706709389521824,val_rmse:0.6538171579031581\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:31:03,873 - INFO - 0,0:320,val_loss:0.25315188243985176,val_rmse:0.7064687274080402\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:31:33,896 - INFO - 0,0:360,val_loss:0.20606912257588975,val_rmse:0.6490103359685936\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:31:36,075 - INFO - [model_fold:0] done in 322 s\n",
      " 20% 1/5 [05:21<21:27, 321.77s/it]/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:31:51,618 - INFO - 0,1:0,val_loss:0.20615593074419633,val_rmse:0.6476175055713682\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:32:21,767 - INFO - 0,1:40,val_loss:0.22574745509319188,val_rmse:0.6663460471284308\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:32:51,878 - INFO - 0,1:80,val_loss:0.2440312601383624,val_rmse:0.6919647482431769\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:33:22,022 - INFO - 0,1:120,val_loss:0.20990525473787533,val_rmse:0.644488141219487\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:33:52,000 - INFO - 0,1:160,val_loss:0.20989783456533906,val_rmse:0.6489048090603974\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:34:22,270 - INFO - 0,1:200,val_loss:0.2062401730960947,val_rmse:0.6441372034460296\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:34:52,212 - INFO - 0,1:240,val_loss:0.20605641800334784,val_rmse:0.6479002304040037\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:35:22,327 - INFO - 0,1:280,val_loss:0.2060669622709596,val_rmse:0.6474061563335437\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:35:52,249 - INFO - 0,1:320,val_loss:0.206054618566986,val_rmse:0.6470728616952762\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:36:22,323 - INFO - 0,1:360,val_loss:0.20647933903506133,val_rmse:0.6465666280999236\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:36:24,505 - INFO - [model_fold:1] done in 288 s\n",
      " 40% 2/5 [10:10<15:06, 302.16s/it]/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:36:40,046 - INFO - 0,2:0,val_loss:0.21622026454263588,val_rmse:0.6540303320194969\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:37:10,223 - INFO - 0,2:40,val_loss:0.2070724547393923,val_rmse:0.6454160980604466\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:37:40,141 - INFO - 0,2:80,val_loss:0.2072127455376028,val_rmse:0.6542862121847893\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:38:10,273 - INFO - 0,2:120,val_loss:0.22151713819826038,val_rmse:0.688609144409833\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:38:40,192 - INFO - 0,2:160,val_loss:0.2088441676725217,val_rmse:0.6470934143381277\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:39:10,322 - INFO - 0,2:200,val_loss:0.21296476266854178,val_rmse:0.6496620063386424\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:39:40,259 - INFO - 0,2:240,val_loss:0.2075003350411004,val_rmse:0.6460912168205618\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:40:10,255 - INFO - 0,2:280,val_loss:0.2070262985440289,val_rmse:0.6463986977780025\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:40:40,198 - INFO - 0,2:320,val_loss:0.2060594380628772,val_rmse:0.6477039443318738\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:41:10,197 - INFO - 0,2:360,val_loss:0.2094794528452846,val_rmse:0.6472972255057486\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:41:12,381 - INFO - [model_fold:2] done in 288 s\n",
      " 60% 3/5 [14:58<09:51, 295.64s/it]/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:41:27,856 - INFO - 0,3:0,val_loss:0.20756414626550868,val_rmse:0.6548140199905615\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:41:57,737 - INFO - 0,3:40,val_loss:0.21075161749391053,val_rmse:0.6485879962936826\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:42:27,763 - INFO - 0,3:80,val_loss:0.2080788119294779,val_rmse:0.6459842779479298\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:42:57,674 - INFO - 0,3:120,val_loss:0.20978155094615328,val_rmse:0.6612605012582861\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:43:27,732 - INFO - 0,3:160,val_loss:0.20690259716011644,val_rmse:0.6462347087809435\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:43:57,656 - INFO - 0,3:200,val_loss:0.20815030969982226,val_rmse:0.6463190462302657\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:44:27,784 - INFO - 0,3:240,val_loss:0.20636776156299483,val_rmse:0.6505367645496588\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:44:57,701 - INFO - 0,3:280,val_loss:0.20641494091085302,val_rmse:0.6463058508987632\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:45:27,715 - INFO - 0,3:320,val_loss:0.2074881606712574,val_rmse:0.6546883594716236\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:45:57,627 - INFO - 0,3:360,val_loss:0.22332044914970553,val_rmse:0.6628526139522307\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:45:59,809 - INFO - [model_fold:3] done in 287 s\n",
      " 80% 4/5 [19:45<04:52, 292.40s/it]/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:46:15,398 - INFO - 0,4:0,val_loss:0.21483850448839065,val_rmse:0.6520554884168429\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:46:45,287 - INFO - 0,4:40,val_loss:0.209858222675275,val_rmse:0.6473808714372938\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:47:15,526 - INFO - 0,4:80,val_loss:0.20931952773797802,val_rmse:0.6468654398652703\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:47:45,385 - INFO - 0,4:120,val_loss:0.20616327462399878,val_rmse:0.6488905985808098\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:48:15,458 - INFO - 0,4:160,val_loss:0.2078414291930877,val_rmse:0.6453204252243628\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:48:45,343 - INFO - 0,4:200,val_loss:0.21007937383724423,val_rmse:0.6468346851067323\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:49:15,571 - INFO - 0,4:240,val_loss:0.20607891918076732,val_rmse:0.6462730928230969\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:49:45,446 - INFO - 0,4:280,val_loss:0.20626375330536345,val_rmse:0.6456456527622693\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:50:15,505 - INFO - 0,4:320,val_loss:0.20718310803659562,val_rmse:0.6450950818926923\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:50:45,392 - INFO - 0,4:360,val_loss:0.20672650929025518,val_rmse:0.6451500187319484\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:921: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "2022-10-16 07:50:47,561 - INFO - [model_fold:4] done in 288 s\n",
      "100% 5/5 [24:33<00:00, 294.65s/it]\n",
      "2022-10-16 07:50:47,565 - INFO - [mpnet] done in 1477 s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"mpnet\"):\n",
    "    set_seed(SEED)\n",
    "    oof = np.zeros([len(train),len(CFG.target_cols)])\n",
    "    for fold in range(4):\n",
    "        x_train, y_train = train.iloc[fold_array !=\n",
    "                                      fold], y.iloc[fold_array != fold]\n",
    "        x_val, y_val = train.iloc[fold_array ==\n",
    "                                  fold], y.iloc[fold_array == fold]\n",
    "\n",
    "        # dataset\n",
    "        train_ = CommonLitDataset(\n",
    "            x_train[CFG.target_cols].values, tokenizer, max_len, y_train.values.reshape(-1, 1))\n",
    "        val_ = CommonLitDataset(\n",
    "            x_val[CFG.target_cols].values, tokenizer, max_len, y_val.values.reshape(-1, 1))\n",
    "\n",
    "        # loader\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "        val_loader = DataLoader(\n",
    "            dataset=val_, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        # model\n",
    "        model = mpnet_model()\n",
    "        model = model.to(device)\n",
    "\n",
    "        # optimizer, scheduler\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(\n",
    "                nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in param_optimizer if any(\n",
    "                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=lr,\n",
    "                          betas=(0.9, 0.98),\n",
    "                          weight_decay=weight_decay,\n",
    "                          )\n",
    "        num_train_optimization_steps = int(len(train_loader) * n_epochs)\n",
    "        num_warmup_steps = int(\n",
    "            num_train_optimization_steps * num_warmup_steps_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=num_warmup_steps,\n",
    "                                                    num_training_steps=num_train_optimization_steps)\n",
    "\n",
    "        criterion = nn.SmoothL1Loss(reduction='mean')\n",
    "        best_val = None\n",
    "        patience = es_patience\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            with timer(f\"model_fold:{epoch}\"):\n",
    "\n",
    "                # train\n",
    "                model.train()\n",
    "                train_losses_batch = []\n",
    "\n",
    "                epoch_loss = 0\n",
    "\n",
    "                for i, d in enumerate(train_loader):\n",
    "\n",
    "                    input_ids = d['input_ids']\n",
    "                    mask = d['attention_mask']\n",
    "                    token_type_ids = d[\"token_type_ids\"]\n",
    "                    target = d[\"target\"]\n",
    "\n",
    "                    input_ids = input_ids.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    token_type_ids = token_type_ids.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output, _ = model(input_ids, mask, token_type_ids)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    train_losses_batch.append(loss.item())\n",
    "\n",
    "                    if i % eval_steps == 0:\n",
    "                        # val\n",
    "                        val_losses_batch = []\n",
    "                        model.eval()  # switch model to the evaluation mode\n",
    "                        val_preds = np.ndarray((0, 6))\n",
    "                        with torch.no_grad():\n",
    "                            # Predicting on validation set\n",
    "                            for d in val_loader:\n",
    "                                # =========================\n",
    "                                # data loader\n",
    "                                # =========================\n",
    "                                input_ids = d['input_ids']\n",
    "                                mask = d['attention_mask']\n",
    "                                token_type_ids = d[\"token_type_ids\"]\n",
    "                                target = d[\"target\"]\n",
    "\n",
    "                                input_ids = input_ids.to(device)\n",
    "                                mask = mask.to(device)\n",
    "                                token_type_ids = token_type_ids.to(device)\n",
    "                                target = target.to(device)\n",
    "                                output, _ = model(\n",
    "                                    input_ids, mask, token_type_ids)\n",
    "\n",
    "                                loss = criterion(output, target)\n",
    "                                val_preds = np.concatenate(\n",
    "                                    [val_preds, output.detach().cpu().numpy()], axis=0)\n",
    "                                val_losses_batch.append(loss.item())\n",
    "\n",
    "                        val_loss = np.mean(val_losses_batch)\n",
    "                        val_rmse = get_score(y_val.to_numpy(), val_preds)[0]\n",
    "                        LOGGER.info(\n",
    "                            f'{fold},{epoch}:{i},val_loss:{val_loss},val_rmse:{val_rmse}')\n",
    "                        # ===================\n",
    "                        # early stop\n",
    "                        # ===================\n",
    "\n",
    "                        if not best_val:\n",
    "                            best_val = val_rmse\n",
    "                \n",
    "                            oof[fold_array == fold] = val_preds\n",
    "                            # Saving the model\n",
    "                            torch.save(model.state_dict(),\n",
    "                                       MODEL_PATH_BASE + f\"_{fold}.pth\")\n",
    "                            continue\n",
    "\n",
    "                        if val_rmse <= best_val:\n",
    "                            best_val = val_rmse\n",
    "                            oof[fold_array == fold] = val_preds\n",
    "                            patience = es_patience\n",
    "                            # Saving current best model\n",
    "                            torch.save(model.state_dict(),\n",
    "                                       MODEL_PATH_BASE + f\"_{fold}.pth\")\n",
    "                        # else:\n",
    "                        #    patience -= 1\n",
    "                        #    if patience == 0:\n",
    "                        #        LOGGER.info(f'Early stopping. Best Val : {best_val} Best Rmse : {best_rmse}')\n",
    "                        #        break\n",
    "                        model.train()\n",
    "\n",
    "                train_loss = np.mean(train_losses_batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4bc24b3-35f1-41bb-adc6-b5bbc302ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6424162115720078,\n",
       " [0.6396375489962369,\n",
       "  0.6429080496628525,\n",
       "  0.5610570605951414,\n",
       "  0.6517650150222908,\n",
       "  0.701356709073021,\n",
       "  0.6577728860825043])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(y_val.to_numpy(),oof[fold_array == fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3ca6d4-8669-4591-8d2d-427ef8c4f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OOF_SAVE_PATH, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd71b8b-9015-47b9-9686-7a852b0c4ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
