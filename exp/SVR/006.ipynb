{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a82b62c",
   "metadata": {
    "papermill": {
     "duration": 0.005405,
     "end_time": "2022-09-10T04:10:35.614972",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.609567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc61465-aaae-4311-bf56-5971abbf7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "TO_KAGGLE = False\n",
    "file_name = \"006\"\n",
    "MEMO = \"10folds,embedding003,004を使用\"\n",
    "model = \"svr\"\n",
    "score_path = \"/home/jupyter/output/scores/scores003.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6b6ea5-0bb5-4038-9467-0672246adf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os, gc, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"svr\"\n",
    "t_delta = datetime.timedelta(hours=9)\n",
    "JST = datetime.timezone(t_delta, 'JST')\n",
    "now = datetime.datetime.now(JST)\n",
    "date = now.strftime('%Y%m%d')\n",
    "date2 = now.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "path =\"/home/jupyter/feedback-prize-english-language-learning/\"\n",
    "if DEBUG:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/DEBUG/{model_name}/{file_name}/{date2}/'\n",
    "else:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/{model_name}/{file_name}/{date2}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84747694",
   "metadata": {
    "papermill": {
     "duration": 0.204385,
     "end_time": "2022-09-10T04:10:35.849631",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.645246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3911, 9) Test shape: (3, 3) Test columns: Index(['text_id', 'full_text', 'src'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions',]\n",
    "\n",
    "dftr = pd.read_csv(\"/home/jupyter/feedback-prize-english-language-learning/train.csv\")\n",
    "dftr[\"src\"]=\"train\"\n",
    "dfte = pd.read_csv(\"/home/jupyter/feedback-prize-english-language-learning/test.csv\")\n",
    "dfte[\"src\"]=\"test\"\n",
    "print('Train shape:',dftr.shape,'Test shape:',dfte.shape,'Test columns:',dfte.columns)\n",
    "df = pd.concat([dftr,dfte],ignore_index=True)\n",
    "\n",
    "fold = pd.read_csv(\"/home/jupyter/output/fold/10folds.csv\")\n",
    "fold.rename(columns={\"fold\":\"FOLD\"},inplace=True)\n",
    "\n",
    "dftr = pd.merge(dftr,fold,how=\"left\",on=\"text_id\")\n",
    "if DEBUG:\n",
    "    dftr = dftr.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345390a",
   "metadata": {
    "papermill": {
     "duration": 0.247107,
     "end_time": "2022-09-10T04:50:15.343807",
     "exception": false,
     "start_time": "2022-09-10T04:50:15.096700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combine Feature Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a0530e-b9fc-4017-a112-da617deb9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/home/jupyter/output/ex/embedding/003/'\n",
    "files_path = []\n",
    "for current_dir, sub_dirs, files_list in os.walk(dir_path): \n",
    "    for file in files_list: \n",
    "        files_path.append(os.path.join(current_dir,file))\n",
    "\n",
    "emb_path = [s for s in files_path if (\"all_embedding.npy\" not in s) and (\"npy\" in s) and (\"mean.npy\" not in s)]\n",
    "cfg_list = [s.split(\"/\")[-1].split(\"_\")[0] for s in emb_path]\n",
    "cfg_list = list(set(cfg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad65000-9f5a-4036-a7da-15c5cd77d11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CFG1', 'CFG2', 'CFG3', 'CFG5', 'CFG4', 'CFG9', 'CFG8', 'CFG6']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffebbeed-7bd3-49da-8091-bd06288c0280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>src</th>\n",
       "      <th>FOLD</th>\n",
       "      <th>pred_cohesion</th>\n",
       "      <th>pred_syntax</th>\n",
       "      <th>pred_vocabulary</th>\n",
       "      <th>pred_phraseology</th>\n",
       "      <th>pred_grammar</th>\n",
       "      <th>pred_conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>2.871366</td>\n",
       "      <td>2.935812</td>\n",
       "      <td>3.052612</td>\n",
       "      <td>2.734635</td>\n",
       "      <td>2.775023</td>\n",
       "      <td>2.529649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3.197907</td>\n",
       "      <td>3.242587</td>\n",
       "      <td>3.245298</td>\n",
       "      <td>3.189578</td>\n",
       "      <td>3.204165</td>\n",
       "      <td>2.920316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3.419058</td>\n",
       "      <td>3.399498</td>\n",
       "      <td>3.388095</td>\n",
       "      <td>3.488686</td>\n",
       "      <td>3.440051</td>\n",
       "      <td>3.197580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916285</td>\n",
       "      <td>2.847148</td>\n",
       "      <td>3.125768</td>\n",
       "      <td>2.692136</td>\n",
       "      <td>2.839136</td>\n",
       "      <td>2.584031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions    src  FOLD  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0  train     9   \n",
       "1     2.5         3.0          2.0      2.0          2.5  train     2   \n",
       "2     3.5         3.0          3.0      3.0          2.5  train     1   \n",
       "3     4.5         4.5          4.5      4.0          5.0  train     1   \n",
       "4     3.0         3.0          3.0      2.5          2.5  train     0   \n",
       "\n",
       "   pred_cohesion  pred_syntax  pred_vocabulary  pred_phraseology  \\\n",
       "0            NaN          NaN              NaN               NaN   \n",
       "1       2.871366     2.935812         3.052612          2.734635   \n",
       "2       3.197907     3.242587         3.245298          3.189578   \n",
       "3       3.419058     3.399498         3.388095          3.488686   \n",
       "4       2.916285     2.847148         3.125768          2.692136   \n",
       "\n",
       "   pred_grammar  pred_conventions  \n",
       "0           NaN               NaN  \n",
       "1      2.775023          2.529649  \n",
       "2      3.204165          2.920316  \n",
       "3      3.440051          3.197580  \n",
       "4      2.839136          2.584031  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92aae340-dd65-49ba-ad4a-3dd9781b47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/home/jupyter/output/ex/embedding/004/'\n",
    "files_path = []\n",
    "for current_dir, sub_dirs, files_list in os.walk(dir_path): \n",
    "    for file in files_list: \n",
    "        files_path.append(os.path.join(current_dir,file))\n",
    "oof_path = [s for s in files_path if \"oof_df.pkl\" in s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5679f3cb-97e5-4c9d-aa13-065388a64f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "all_oof_feats = pd.read_pickle(oof_path[1])\n",
    "all_oof_feats = pd.merge(dftr[\"text_id\"],all_oof_feats,how=\"left\",on=\"text_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c1aaf65-9d45-439e-ba56-f5f7e9806524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_cohesion</th>\n",
       "      <th>pred_syntax</th>\n",
       "      <th>pred_vocabulary</th>\n",
       "      <th>pred_phraseology</th>\n",
       "      <th>pred_grammar</th>\n",
       "      <th>pred_conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.427323</td>\n",
       "      <td>2.465084</td>\n",
       "      <td>2.687973</td>\n",
       "      <td>2.440547</td>\n",
       "      <td>2.555911</td>\n",
       "      <td>2.336514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00ED2563D0B1</td>\n",
       "      <td>Philosopher, physician, and humanitarian Alber...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.800885</td>\n",
       "      <td>3.851415</td>\n",
       "      <td>3.941611</td>\n",
       "      <td>3.819339</td>\n",
       "      <td>3.906917</td>\n",
       "      <td>3.766028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text_id                                          full_text  cohesion  \\\n",
       "4   0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "13  00ED2563D0B1  Philosopher, physician, and humanitarian Alber...       3.5   \n",
       "\n",
       "    syntax  vocabulary  phraseology  grammar  conventions  fold  \\\n",
       "4      3.0         3.0          3.0      2.5          2.5     0   \n",
       "13     3.0         3.5          3.5      3.5          4.0     0   \n",
       "\n",
       "    pred_cohesion  pred_syntax  pred_vocabulary  pred_phraseology  \\\n",
       "4        2.427323     2.465084         2.687973          2.440547   \n",
       "13       3.800885     3.851415         3.941611          3.819339   \n",
       "\n",
       "    pred_grammar  pred_conventions  \n",
       "4       2.555911          2.336514  \n",
       "13      3.906917          3.766028  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_oof_feats.loc[all_oof_feats.fold==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905a9a2b-55dc-40f1-845f-ef05ff9a69c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_169/1898585303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_oof_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moof_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                 raise ValueError(\"Cannot load file containing pickled data \"\n\u001b[0m\u001b[1;32m    446\u001b[0m                                  \"when allow_pickle=False\")\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "all_oof_feats = pd.read_pickle(oof_path[0])\n",
    "for path in oof_path[1:]:\n",
    "    oof = pd.read_pickle(path)\n",
    "    all_oof_feats = np.concatenate([all_oof_feats,oof],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c4b3e",
   "metadata": {
    "papermill": {
     "duration": 0.264229,
     "end_time": "2022-09-10T04:50:16.564156",
     "exception": false,
     "start_time": "2022-09-10T04:50:16.299927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train RAPIDS cuML SVR\n",
    "Documentation for RAPIDS SVM is [here][1]\n",
    "\n",
    "[1]: https://docs.rapids.ai/api/cuml/stable/api.html#support-vector-machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bc3009",
   "metadata": {
    "papermill": {
     "duration": 3.271607,
     "end_time": "2022-09-10T04:50:20.094636",
     "exception": false,
     "start_time": "2022-09-10T04:50:16.823029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAPIDS version 21.10.02\n"
     ]
    }
   ],
   "source": [
    "from cuml.svm import SVR\n",
    "import cuml\n",
    "print('RAPIDS version',cuml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c80e039-e60c-4223-8aff-d90fa03a75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_result2(oof_df):\n",
    "    labels = oof_df[target_cols].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in target_cols]].values\n",
    "    score, scores = get_score(labels, preds)\n",
    "    #LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
    "    return score,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea265113",
   "metadata": {
    "papermill": {
     "duration": 39.329447,
     "end_time": "2022-09-10T04:50:59.673871",
     "exception": false,
     "start_time": "2022-09-10T04:50:20.344424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "#########################\n",
      "\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 0 RSME score: 0.3149222462188594\n",
      "#########################\n",
      "### Fold 2\n",
      "#########################\n",
      "\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 1 RSME score: 0.7744570741558268\n",
      "#########################\n",
      "### Fold 3\n",
      "#########################\n",
      "\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 2 RSME score: 0.4339269762270967\n",
      "#########################\n",
      "### Fold 4\n",
      "#########################\n",
      "\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 3 RSME score: 0.47482786198442595\n",
      "#########################\n",
      "### Fold 5\n",
      "#########################\n",
      "\n",
      "cohesion , "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "UnownedMemory requires explicit device ID for a null pointer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_169/738978362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mev_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mev_text_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"pred_{t}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cuml/internals/api_decorators.py\u001b[0m in \u001b[0;36minner_get\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                 \u001b[0;31m# Call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcuml/svm/svr.pyx\u001b[0m in \u001b[0;36mcuml.svm.svr.SVR.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cuml/internals/api_decorators.py\u001b[0m in \u001b[0;36minner_get\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                 \u001b[0;31m# Call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcuml/svm/svm_base.pyx\u001b[0m in \u001b[0;36mcuml.svm.svm_base.SVMBase.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cuml/internals/api_decorators.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cuml/common/input_utils.py\u001b[0m in \u001b[0;36minput_to_cuml_array\u001b[0;34m(X, order, deepcopy, check_dtype, convert_to_dtype, safe_dtype_conversion, check_cols, check_rows, fail_on_order, force_contiguous)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheck_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mX_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mX_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCumlArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/cupy/_creation/from_data.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(obj, dtype, copy, order, subok, ndmin)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core._array_from_cuda_array_interface\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core._convert_object_with_cuda_array_interface\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.UnownedMemory.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: UnownedMemory requires explicit device ID for a null pointer."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "scores = []\n",
    "def comp_score(y_true,y_pred):\n",
    "    rmse_scores = []\n",
    "    for i in range(len(target_cols)):\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_true[:,i],y_pred[:,i])))\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "#for fold in tqdm(range(FOLDS),total=FOLDS):\n",
    "for fold in range(dftr.FOLD.nunique()):\n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    dftr_ = dftr[dftr[\"FOLD\"]!=fold]\n",
    "    dfev_ = dftr[dftr[\"FOLD\"]==fold]\n",
    "    \n",
    "    _ = [s for s in emb_path if f\"fold{fold}\" in s]\n",
    "    all_train_text_feats = np.load(_[0])\n",
    "    for path in _[1:]:\n",
    "        emb = np.load(path)\n",
    "        all_train_text_feats = np.concatenate([all_train_text_feats,emb],axis=1)\n",
    "\n",
    "    if DEBUG:\n",
    "        print()\n",
    "        all_train_text_feats = all_train_text_feats[:20]\n",
    "\n",
    "    tr_text_feats = all_train_text_feats[list(dftr_.index),:]\n",
    "    ev_text_feats = all_train_text_feats[list(dfev_.index),:]\n",
    "    \n",
    "    ev_preds = np.zeros((len(ev_text_feats),6))\n",
    "    for i,t in enumerate(target_cols):\n",
    "        print(t,', ',end='')\n",
    "        modelname = OUTPUT_DIR+f'svr_{t}_fold{fold}.sav'\n",
    "        clf = SVR(C=1)\n",
    "        clf.fit(tr_text_feats, dftr_[t].values)\n",
    "        joblib.dump(clf, modelname)\n",
    "        loaded_model = joblib.load(modelname)\n",
    "        ev_preds[:,i] = loaded_model .predict(ev_text_feats)\n",
    "        \n",
    "    cols = [f\"pred_{t}\" for t in target_cols]\n",
    "    dftr.loc[list(dfev_.index),cols] = ev_preds\n",
    "    print()\n",
    "    score = comp_score(dfev_[target_cols].values,ev_preds)\n",
    "    scores.append(score)\n",
    "    print(\"Fold : {} RSME score: {}\".format(fold,score))\n",
    "\n",
    "dftr.to_pickle(OUTPUT_DIR+f'oof_df.pkl')\n",
    "score,scores = get_result2(dftr)\n",
    "print('#'*25)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bac531-5add-4405-9858-304c7cc084fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TO_KAGGLE:\n",
    "    UPLOAD_DIR = OUTPUT_DIR\n",
    "    EX_NO = f\"{model}-{file_name}\" # 実験番号などを入れる、folderのpathにする\n",
    "    USERID = 'your_id'\n",
    "\n",
    "\n",
    "    def dataset_upload():\n",
    "        import json\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "        id = f'{USERID}/{EX_NO}'\n",
    "\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata['id'] = id\n",
    "        dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "        dataset_metadata['title'] = f'{EX_NO}'\n",
    "\n",
    "        with open(UPLOAD_DIR +'dataset-metadata.json', 'w') as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "\n",
    "        # データセットがない場合\n",
    "        if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
    "            api.dataset_create_new(folder=UPLOAD_DIR,\n",
    "                                   convert_to_csv=False,\n",
    "                                   dir_mode='skip')\n",
    "            \n",
    "            #apiコマンドを書き込む\n",
    "            f = open(f'{model}_api_command.txt', 'a')\n",
    "            api_command = f\"!kaggle datasets download -d hiroki8383/{EX_NO}\\n\"\n",
    "            f.write(api_command)\n",
    "            f.close()\n",
    "            \n",
    "            #フォルダーを削除\n",
    "            if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
    "                remove_files = glob.glob(OUTPUT_DIR+\"*\")\n",
    "                remove_files.remove(OUTPUT_DIR+\"oof_df.pkl\")\n",
    "                for file in remove_files:\n",
    "                    os.remove(file)\n",
    "                print(\"folder upload\")\n",
    "            else:\n",
    "                print(\"folder not upload\")\n",
    "            \n",
    "            \n",
    "        # データセットがある場合→更新されない場合がある（後で原因追及)\n",
    "        else:\n",
    "            print(\"this folder exsits\")\n",
    "            # api.dataset_create_version(folder=UPLOAD_DIR,\n",
    "            #                            version_notes='update',\n",
    "            #                            convert_to_csv=False,\n",
    "            #                            delete_old_versions=False,\n",
    "            #                            dir_mode='zip')\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    dataset_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e5f1f-6531-4bc0-a3b3-d611db21a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c07ab5-a53d-4aab-b573-6718f0486897",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMO = \"10folds,embedding003を使用\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61e0a1-164b-468b-bb8b-546c42ca7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    def to_write_score(MEMO,score_path):\n",
    "        df = pd.read_csv(score_path)\n",
    "        def get_result2(oof_df):\n",
    "                labels = oof_df[target_cols].values\n",
    "                preds = oof_df[[f\"pred_{c}\" for c in target_cols]].values\n",
    "                score, scores = get_score(labels, preds)\n",
    "                #LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
    "                return score,scores\n",
    "\n",
    "        score,scores = get_result2(dftr)\n",
    "        name = \"-\".join(OUTPUT_DIR.split(\"/\")[-4:-2])\n",
    "        base = {\"name\":name,\"score\":score,\"memo\":MEMO} \n",
    "        base.update(dict(zip(target_cols,scores)))\n",
    "        df = df.append(base,ignore_index=True).sort_values(by=\"name\").reset_index(drop=True)\n",
    "        df.to_csv(score_path,index=False)\n",
    "    to_write_score(MEMO,score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654c3a9-8a3e-4dec-bcce-235a3a992625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(score_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396babe-3694-49f2-ada0-e4335ca327d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(ascending=True,by=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9f724-b930-4acb-8100-73249676b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.name.isin([n for n in df.name if \"roberta\" in n])].sort_values(ascending=True,by=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae9015-211c-4a43-8cff-9fdad85174d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2437.583821,
   "end_time": "2022-09-10T04:51:05.260170",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-10T04:10:27.676349",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
