{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e134303b",
   "metadata": {
    "papermill": {
     "duration": 7.390392,
     "end_time": "2022-11-11T06:12:42.243131",
     "exception": false,
     "start_time": "2022-11-11T06:12:34.852739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.__version__: 4.20.1\n",
      "tokenizers.__version__: 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "from distutils.util import strtobool\n",
    "import warnings\n",
    "import glob\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import transformers\n",
    "import tokenizers\n",
    "print(f'transformers.__version__: {transformers.__version__}')\n",
    "print(f'tokenizers.__version__: {tokenizers.__version__}')\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "os.environ['TOKENIZERS_PARALLELISM']='true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898644d3",
   "metadata": {
    "papermill": {
     "duration": 0.005823,
     "end_time": "2022-11-11T06:12:42.255630",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.249807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd528b0",
   "metadata": {
    "papermill": {
     "duration": 0.019257,
     "end_time": "2022-11-11T06:12:42.280934",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.261677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    TO_KAGGLE = True\n",
    "    debug = True\n",
    "    file_name = \"005\"\n",
    "    model = 'microsoft/deberta-v3-large'\n",
    "    score_path = \"gs://feedback3/output/scores/scores3.csv\"\n",
    "    #models_path = 'FB3-models'\n",
    "    epochs = 10\n",
    "    patience = 3\n",
    "    competition = 'FB3'\n",
    "    train = True\n",
    "    save_all_models = False\n",
    "    offline = False\n",
    "    apex = True\n",
    "    print_freq = 20\n",
    "    num_workers = 4\n",
    "    loss_func = 'SmoothL1' # 'SmoothL1', 'RMSE'\n",
    "    gradient_checkpointing = True\n",
    "    scheduler = 'cosine'\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5\n",
    "    num_warmup_steps = 0\n",
    "    encoder_lr = 2e-5\n",
    "    decoder_lr = 2e-5\n",
    "    min_lr = 1e-6\n",
    "    #Layer-Wise Learning Rate Decay\n",
    "    llrd = True\n",
    "    layerwise_lr = 5e-5\n",
    "    layerwise_lr_decay = 0.9\n",
    "    layerwise_weight_decay = 0.01\n",
    "    layerwise_adam_epsilon = 1e-6\n",
    "    layerwise_use_bertadam = False\n",
    "    #pooling\n",
    "    pooling = 'attention' # mean, max, min, attention, weightedlayer\n",
    "    layer_start = 4\n",
    "    #init_weight\n",
    "    init_weight = 'normal' # normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal\n",
    "    #re-init\n",
    "    reinit = True\n",
    "    reinit_n = 1\n",
    "    #adversarial\n",
    "    fgm = True\n",
    "#     awp = False\n",
    "    adv_lr = 1\n",
    "    adv_eps = 0.2\n",
    "    unscale = False\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    max_len = 512\n",
    "    weight_decay = 0.01\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed = 42\n",
    "    cv_seed = 42\n",
    "    n_fold = 10\n",
    "    trn_fold = list(range(n_fold))\n",
    "    batch_size = 8\n",
    "    n_targets = 6\n",
    "    gpu_id = 0\n",
    "    device = f'cuda:{gpu_id}'\n",
    "    train_file = '/home/jupyter/feedback-prize-english-language-learning/train.csv'\n",
    "    test_file = '/home/jupyter/feedback-prize-english-language-learning/test.csv'\n",
    "    submission_file = '/home/jupyter/feedback-prize-english-language-learning/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1313d603",
   "metadata": {
    "papermill": {
     "duration": 0.016194,
     "end_time": "2022-11-11T06:12:42.303134",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.286940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Unique model name\n",
    "# if len(CFG.model.split(\"/\")) == 2:\n",
    "#     CFG.identifier = f'{CFG.str_now}-{CFG.model.split(\"/\")[1]}'\n",
    "# else:\n",
    "#     CFG.identifier = f'{CFG.str_now}-{CFG.model}'\n",
    "    \n",
    "# print(CFG.identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244524b",
   "metadata": {
    "papermill": {
     "duration": 0.005802,
     "end_time": "2022-11-11T06:12:42.316843",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.311041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read train and split with MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6941bc3d-4870-4558-8cd1-5517622d90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# datetime\n",
    "# ====================================================\n",
    "t_delta = datetime.timedelta(hours=9)\n",
    "JST = datetime.timezone(t_delta, 'JST')\n",
    "now = datetime.datetime.now(JST)\n",
    "date = now.strftime('%Y%m%d')\n",
    "date2 = now.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# file_path\n",
    "# ====================================================\n",
    "if \"/\" in CFG.model:\n",
    "    model_name = CFG.model.split(\"/\")[1]\n",
    "else:\n",
    "    model_name = CFG.model\n",
    "\n",
    "path =\"/home/jupyter/feedback-prize-english-language-learning/\"\n",
    "if CFG.debug:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/DEBUG/{model_name}/{CFG.file_name}/{date2}/'\n",
    "else:\n",
    "    OUTPUT_DIR = f'/home/jupyter/output/ex/{model_name}/{CFG.file_name}/{date2}/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47255adf",
   "metadata": {
    "papermill": {
     "duration": 10.294485,
     "end_time": "2022-11-11T06:12:52.617208",
     "exception": false,
     "start_time": "2022-11-11T06:12:42.322723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification==0.1.7 in /opt/conda/lib/python3.7/site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification==0.1.7) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/output/ex/DEBUG/deberta-v3-large/005/202211120111/\n"
     ]
    }
   ],
   "source": [
    "if CFG.train:\n",
    "    CFG.df_train = pd.read_csv(CFG.train_file)\n",
    "    CFG.OUTPUT_DIR = OUTPUT_DIR\n",
    "    CFG.log_filename = CFG.OUTPUT_DIR + 'train'\n",
    "    if CFG.offline:\n",
    "        #TO DO\n",
    "        pass\n",
    "    else:\n",
    "        os.system('pip install iterative-stratification==0.1.7')\n",
    "    #CV\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold    \n",
    "    Fold = MultilabelStratifiedKFold(n_splits = CFG.n_fold, shuffle = True, random_state = CFG.cv_seed)\n",
    "    fold = np.load(\"/home/jupyter/output/fold/4fold.npy\")\n",
    "    CFG.df_train['fold'] = fold\n",
    "    CFG.df_train['fold'] = CFG.df_train['fold'].astype(int)\n",
    "else:\n",
    "    #TO DO\n",
    "    pass\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0]\n",
    "    if CFG.train:\n",
    "        CFG.df_train = CFG.df_train.sample(n = 100, random_state = CFG.seed).reset_index(drop=True)\n",
    "        \n",
    "os.makedirs(CFG.OUTPUT_DIR, exist_ok=True)    \n",
    "print(CFG.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11682f",
   "metadata": {
    "papermill": {
     "duration": 0.006326,
     "end_time": "2022-11-11T06:12:52.631392",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.625066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75785677",
   "metadata": {
    "papermill": {
     "duration": 0.029511,
     "end_time": "2022-11-11T06:12:52.667341",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.637830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:, i]\n",
    "        y_pred = y_preds[:, i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared = False)\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_logger(filename = CFG.log_filename):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter('%(message)s'))\n",
    "    handler2 = FileHandler(filename = f'{filename}.log')\n",
    "    handler2.setFormatter(Formatter('%(message)s'))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors = None,\n",
    "        add_special_tokens = True,\n",
    "        max_length = cfg.max_len,\n",
    "        pad_to_max_length = True,\n",
    "        truncation = True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs    \n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs['attention_mask'].sum(axis = 1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n = 1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{int(m)}m {int(s)}s'\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return f'{str(asMinutes(s))} (remain {str(asMinutes(rs))})'\n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, reduction = 'mean', eps = 1e-9):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction = 'none')\n",
    "        self.reduction = reduction\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n",
    "        if self.reduction == 'none':\n",
    "            loss = loss\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        return loss\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefff92",
   "metadata": {
    "papermill": {
     "duration": 0.006217,
     "end_time": "2022-11-11T06:12:52.680127",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.673910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pooling\n",
    "\n",
    "* Attention pooling (https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678)\n",
    "* WeightedLayerPooling (https://www.kaggle.com/code/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning?scriptVersionId=67176591&cellId=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55c7d23",
   "metadata": {
    "papermill": {
     "duration": 0.026848,
     "end_time": "2022-11-11T06:12:52.713183",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.686335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n",
    "        mean_embeddings = sum_embeddings/sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class MaxPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        embeddings = last_hidden_state.clone()\n",
    "        embeddings[input_mask_expanded == 0] = -1e4\n",
    "        max_embeddings, _ = torch.max(embeddings, dim = 1)\n",
    "        return max_embeddings\n",
    "    \n",
    "class MinPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        embeddings = last_hidden_state.clone()\n",
    "        embeddings[input_mask_expanded == 0] = 1e-4\n",
    "        min_embeddings, _ = torch.min(embeddings, dim = 1)\n",
    "        return min_embeddings\n",
    "\n",
    "#Attention pooling\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "        nn.Linear(in_dim, in_dim),\n",
    "        nn.LayerNorm(in_dim),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(in_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        w = self.attention(last_hidden_state).float()\n",
    "        w[attention_mask==0]=float('-inf')\n",
    "        w = torch.softmax(w,1)\n",
    "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
    "        return attention_embeddings\n",
    "\n",
    "#There may be a bug in my implementation because it does not work well.\n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, ft_all_layers):\n",
    "        all_layer_embedding = torch.stack(ft_all_layers)\n",
    "        all_layer_embedding = all_layer_embedding[self.layer_start:, :, :, :]\n",
    "\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "\n",
    "        return weighted_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649abb3",
   "metadata": {
    "papermill": {
     "duration": 0.006334,
     "end_time": "2022-11-11T06:12:52.725984",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.719650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fast Gradient Method (FGM)\n",
    "Reference :\n",
    "\n",
    "https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b30761",
   "metadata": {
    "papermill": {
     "duration": 0.01792,
     "end_time": "2022-11-11T06:12:52.750455",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.732535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon = 1., emb_name = 'word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name = 'word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "            self.backup = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52647d6b",
   "metadata": {
    "papermill": {
     "duration": 0.006203,
     "end_time": "2022-11-11T06:12:52.763514",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.757311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train function\n",
    "* FGM\n",
    "* Unscale optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e36764",
   "metadata": {
    "papermill": {
     "duration": 0.021948,
     "end_time": "2022-11-11T06:12:52.792023",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.770075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled = CFG.apex)\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    if CFG.fgm:\n",
    "        fgm = FGM(model)\n",
    "#     if CFG.awp:\n",
    "#         awp = AWP(model,\n",
    "#                   optimizer, \n",
    "#                   adv_lr = CFG.adv_lr, \n",
    "#                   adv_eps = CFG.adv_eps, \n",
    "#                   scaler = scaler)\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled = CFG.apex):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        if CFG.unscale:\n",
    "            scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        #Fast Gradient Method (FGM)\n",
    "        if CFG.fgm:\n",
    "            fgm.attack()\n",
    "            with torch.cuda.amp.autocast(enabled = CFG.apex):\n",
    "                y_preds = model(inputs)\n",
    "                loss_adv = criterion(y_preds, labels)\n",
    "                loss_adv.backward()\n",
    "            fgm.restore()\n",
    "            \n",
    "        #Adversarial Weight Perturbation (AWP)\n",
    "#         if CFG.awp:\n",
    "#             loss_awp = awp.attack_backward(inputs, labels, attention_mask, step + 1)\n",
    "#             loss_awp.backward()\n",
    "#             awp._restore()\n",
    "        \n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f} '\n",
    "                  'LR: {lr:.8f} '\n",
    "                  .format(epoch + 1, step, len(train_loader), remain = timeSince(start, float(step + 1)/len(train_loader)),\n",
    "                          loss = losses,\n",
    "                          grad_norm = grad_norm,\n",
    "                          lr = scheduler.get_lr()[0]\n",
    "                         )\n",
    "                 )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4dee2",
   "metadata": {
    "papermill": {
     "duration": 0.006085,
     "end_time": "2022-11-11T06:12:52.804243",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.798158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e5d7e26",
   "metadata": {
    "papermill": {
     "duration": 0.018106,
     "end_time": "2022-11-11T06:12:52.828802",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.810696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss = losses,\n",
    "                          remain = timeSince(start, float(step + 1) / len(valid_loader))\n",
    "                         )\n",
    "                 )\n",
    "    return losses.avg, np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6a997",
   "metadata": {
    "papermill": {
     "duration": 0.006992,
     "end_time": "2022-11-11T06:12:52.844588",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.837596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14590fbc",
   "metadata": {
    "papermill": {
     "duration": 0.015217,
     "end_time": "2022-11-11T06:12:52.866248",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.851031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OUTPUT_DIR: /home/jupyter/output/ex/DEBUG/deberta-v3-large/005/202211120111/\n"
     ]
    }
   ],
   "source": [
    "LOGGER = get_logger()\n",
    "LOGGER.info(f'OUTPUT_DIR: {CFG.OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424df24",
   "metadata": {
    "papermill": {
     "duration": 0.006113,
     "end_time": "2022-11-11T06:12:52.878785",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.872672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a68f01",
   "metadata": {
    "papermill": {
     "duration": 9.761103,
     "end_time": "2022-11-11T06:13:02.646289",
     "exception": false,
     "start_time": "2022-11-11T06:12:52.885186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d3835667ea4d22823a3cb4b573f227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 1358\n"
     ]
    }
   ],
   "source": [
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "#CFG.tokenizer.save_pretrained(CFG.OUTPUT_DIR + 'tokenizer')\n",
    "\n",
    "#max_len\n",
    "lengths = []\n",
    "tk0 = tqdm(CFG.df_train['full_text'].fillna('').values, total = len(CFG.df_train))\n",
    "for text in tk0:\n",
    "    length = len(CFG.tokenizer(text, add_special_tokens = False)['input_ids'])\n",
    "    lengths.append(length)\n",
    "CFG.max_len = max(lengths) + 2\n",
    "LOGGER.info(f'max_len: {CFG.max_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d92867",
   "metadata": {
    "papermill": {
     "duration": 0.006808,
     "end_time": "2022-11-11T06:13:02.660860",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.654052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bfd3979",
   "metadata": {
    "papermill": {
     "duration": 0.017173,
     "end_time": "2022-11-11T06:13:02.685013",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.667840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FB3TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['full_text'].values\n",
    "        self.labels = df[cfg.target_cols].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        label = torch.tensor(self.labels[item], dtype = torch.float)\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5d446",
   "metadata": {
    "papermill": {
     "duration": 0.00666,
     "end_time": "2022-11-11T06:13:02.698928",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.692268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "\n",
    "* Initializing module (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal) \n",
    "* Freeze lower layer when you use large model (v2-xlarge, funnnel, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7d3ec1",
   "metadata": {
    "papermill": {
     "duration": 0.034698,
     "end_time": "2022-11-11T06:13:02.740521",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.705823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FB3Model(nn.Module):\n",
    "    def __init__(self, CFG, config_path = None, pretrained = False):\n",
    "        super().__init__()\n",
    "        self.CFG = CFG\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(CFG.model, ouput_hidden_states = True)\n",
    "            #self.config.save_pretrained(CFG.OUTPUT_DIR + 'config')\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "            \n",
    "        LOGGER.info(self.config)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(CFG.model, config=self.config)\n",
    "            #self.model.save_pretrained(CFG.OUTPUT_DIR + 'model')\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "            \n",
    "        if self.CFG.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "            \n",
    "        if CFG.pooling == 'mean':\n",
    "            self.pool = MeanPooling()\n",
    "        elif CFG.pooling == 'max':\n",
    "            self.pool = MaxPooling()\n",
    "        elif CFG.pooling == 'min':\n",
    "            self.pool = MinPooling()\n",
    "        elif CFG.pooling == 'attention':\n",
    "            self.pool = AttentionPooling(self.config.hidden_size)\n",
    "        elif CFG.pooling == 'weightedlayer':\n",
    "            self.pool = WeightedLayerPooling(self.config.num_hidden_layers, layer_start = CFG.layer_start, layer_weights = None)        \n",
    "        \n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.CFG.n_targets)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if 'deberta-v2-xxlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:24].requires_grad_(False)\n",
    "        if 'deberta-v2-xlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:12].requires_grad_(False)\n",
    "        if 'funnel-transformer-xlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.blocks[:1].requires_grad_(False)\n",
    "        if 'funnel-transformer-large' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.blocks[:1].requires_grad_(False)\n",
    "        if 'deberta-large' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:16].requires_grad_(False)\n",
    "        if 'deberta-xlarge' in CFG.model:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:36].requires_grad_(False)\n",
    "            \n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        if CFG.pooling != 'weightedlayer':\n",
    "            last_hidden_states = outputs[0]\n",
    "            feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        else:\n",
    "            all_layer_embeddings = outputs[1]\n",
    "            feature = self.pool(all_layer_embeddings)\n",
    "            \n",
    "        return feature\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        outout = self.fc(feature)\n",
    "        return outout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778f3e5",
   "metadata": {
    "papermill": {
     "duration": 0.007378,
     "end_time": "2022-11-11T06:13:02.754997",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.747619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "* Re-initializing upper layer (normal, xavier_uniform, xavier_normal, kaiming_uniform, kaiming_normal, orthogonal) \n",
    "* Layer-Wise Learning Rate Dacay (https://www.kaggle.com/code/rhtsingh/on-stability-of-few-sample-transformer-fine-tuning?scriptVersionId=67176591&cellId=29)\n",
    "* Loss function, SmoothL1 or RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f07471",
   "metadata": {
    "papermill": {
     "duration": 0.044129,
     "end_time": "2022-11-11T06:13:02.806409",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.762280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def re_initializing_layer(model, config, layer_num):\n",
    "    for module in model.model.encoder.layer[-layer_num:].modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data) \n",
    "                \n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    return model   \n",
    "\n",
    "def train_loop(folds, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    \n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop = True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop = True)\n",
    "    valid_labels = valid_folds[CFG.target_cols].values\n",
    "    \n",
    "    train_dataset = FB3TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = FB3TrainDataset(CFG, valid_folds)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size = CFG.batch_size,\n",
    "                              shuffle = True, \n",
    "                              num_workers = CFG.num_workers,\n",
    "                              pin_memory = True, \n",
    "                              drop_last = True\n",
    "                             )\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size = CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True, \n",
    "                              drop_last=False)\n",
    "\n",
    "    model = FB3Model(CFG, config_path = None, pretrained = True)\n",
    "    if CFG.reinit:\n",
    "        model = re_initializing_layer(model, model.config, CFG.reinit_n)\n",
    "        \n",
    "    #os.makedirs(CFG.OUTPUT_DIR + 'config/', exist_ok = True)\n",
    "    #torch.save(model.config, CFG.OUTPUT_DIR + 'config/config.pth')\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    def get_optimizer_params(model,\n",
    "                             encoder_lr,\n",
    "                             decoder_lr,\n",
    "                             weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr,\n",
    "             'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr,\n",
    "             'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr,\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "    \n",
    "    #llrd\n",
    "    def get_optimizer_grouped_parameters(model, \n",
    "                                         layerwise_lr,\n",
    "                                         layerwise_weight_decay,\n",
    "                                         layerwise_lr_decay):\n",
    "        \n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        # initialize lr for task specific layer\n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "                                         \"weight_decay\": 0.0,\n",
    "                                         \"lr\": layerwise_lr,\n",
    "                                        },]\n",
    "        # initialize lrs for every layer\n",
    "        layers = [model.model.embeddings] + list(model.model.encoder.layer)\n",
    "        layers.reverse()\n",
    "        lr = layerwise_lr\n",
    "        for layer in layers:\n",
    "            optimizer_grouped_parameters += [{\"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                                              \"weight_decay\": layerwise_weight_decay,\n",
    "                                              \"lr\": lr,\n",
    "                                             },\n",
    "                                             {\"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                                              \"weight_decay\": 0.0,\n",
    "                                              \"lr\": lr,\n",
    "                                             },]\n",
    "            lr *= layerwise_lr_decay\n",
    "        return optimizer_grouped_parameters\n",
    "    \n",
    "    if CFG.llrd:\n",
    "        from transformers import AdamW\n",
    "        grouped_optimizer_params = get_optimizer_grouped_parameters(model, \n",
    "                                                                    CFG.layerwise_lr, \n",
    "                                                                    CFG.layerwise_weight_decay, \n",
    "                                                                    CFG.layerwise_lr_decay)\n",
    "        optimizer = AdamW(grouped_optimizer_params,\n",
    "                          lr = CFG.layerwise_lr,\n",
    "                          eps = CFG.layerwise_adam_epsilon,\n",
    "                          correct_bias = not CFG.layerwise_use_bertadam)\n",
    "    else:\n",
    "        from torch.optim import AdamW\n",
    "        optimizer_parameters = get_optimizer_params(model,\n",
    "                                                    encoder_lr=CFG.encoder_lr, \n",
    "                                                    decoder_lr=CFG.decoder_lr,\n",
    "                                                    weight_decay=CFG.weight_decay)\n",
    "        optimizer = AdamW(optimizer_parameters, \n",
    "                          lr=CFG.encoder_lr,\n",
    "                          eps=CFG.eps,\n",
    "                          betas=CFG.betas)\n",
    "    \n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, \n",
    "                num_warmup_steps = cfg.num_warmup_steps, \n",
    "                num_training_steps = num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, \n",
    "                num_warmup_steps = cfg.num_warmup_steps, \n",
    "                num_training_steps = num_train_steps,\n",
    "                num_cycles = cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "    \n",
    "    if CFG.loss_func == 'SmoothL1':\n",
    "        criterion = nn.SmoothL1Loss(reduction='mean')\n",
    "    elif CFG.loss_func == 'RMSE':\n",
    "        criterion = RMSELoss(reduction='mean')\n",
    "    \n",
    "    best_score = np.inf\n",
    "    best_train_loss = np.inf\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    epoch_list = []\n",
    "    epoch_avg_loss_list = []\n",
    "    epoch_avg_val_loss_list = []\n",
    "    epoch_score_list = []\n",
    "    epoch_scores_list = []\n",
    "    patience = CFG.patience\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        \n",
    "        # scoring\n",
    "        score, scores = get_score(valid_labels, predictions)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
    "        \n",
    "        epoch_list.append(epoch+1)\n",
    "        epoch_avg_loss_list.append(avg_loss)\n",
    "        epoch_avg_val_loss_list.append(avg_val_loss)\n",
    "        epoch_score_list.append(score)\n",
    "        epoch_scores_list.append(scores)\n",
    "        \n",
    "        if best_score > score:\n",
    "            patience = CFG.patience\n",
    "            best_score = score\n",
    "            best_train_loss = avg_loss\n",
    "            best_val_loss = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience<=0:\n",
    "                break\n",
    "            \n",
    "        if CFG.save_all_models:\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_epoch{epoch + 1}.pth\")\n",
    "\n",
    "    predictions = torch.load(CFG.OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location = torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "    \n",
    "    df_epoch = pd.DataFrame({'epoch' : epoch_list,\n",
    "                             'MCRMSE' : epoch_score_list,\n",
    "                             'train_loss' : epoch_avg_loss_list, \n",
    "                             'val_loss' : epoch_avg_val_loss_list})\n",
    "    df_scores = pd.DataFrame(epoch_scores_list)\n",
    "    df_scores.columns = CFG.target_cols\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return best_train_loss, best_val_loss, valid_folds, pd.concat([df_epoch, df_scores], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188efa9",
   "metadata": {
    "papermill": {
     "duration": 0.00738,
     "end_time": "2022-11-11T06:13:02.821185",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.813805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f247e098",
   "metadata": {
    "papermill": {
     "duration": 0.02245,
     "end_time": "2022-11-11T06:13:02.850607",
     "exception": false,
     "start_time": "2022-11-11T06:13:02.828157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_result(oof_df, fold, best_train_loss, best_val_loss):\n",
    "    labels = oof_df[CFG.target_cols].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
    "    score, scores = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
    "    _output_log = pd.DataFrame([f\"{model_name}-{CFG.file_name}\", CFG.model, CFG.cv_seed, CFG.seed, fold, 'best', score, best_train_loss, best_val_loss] + scores).T\n",
    "    _output_log.columns = ['file', 'model', 'cv_seed', 'seed', 'fold', 'epoch', 'MCRMSE', 'train_loss', 'val_loss'] + CFG.target_cols\n",
    "    return _output_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.train:\n",
    "    output_log = pd.DataFrame()\n",
    "    oof_df = pd.DataFrame()\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    for fold in range(CFG.n_fold):\n",
    "        if fold in CFG.trn_fold:\n",
    "            best_train_loss, best_val_loss, _oof_df, df_epoch_scores = train_loop(CFG.df_train, fold)\n",
    "            train_loss_list.append(best_train_loss)\n",
    "            val_loss_list.append(best_val_loss)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "\n",
    "            df_epoch_scores['file'] = f\"{model_name}-{CFG.file_name}\"\n",
    "            df_epoch_scores['model'] = CFG.model\n",
    "            df_epoch_scores['cv_seed'] = CFG.cv_seed\n",
    "            df_epoch_scores['seed'] = CFG.seed\n",
    "            df_epoch_scores['fold'] = fold\n",
    "            df_epoch_scores = df_epoch_scores[['file', 'model', 'cv_seed', 'seed', 'fold', 'epoch', 'MCRMSE', 'train_loss', 'val_loss'] + CFG.target_cols]\n",
    "\n",
    "            _output_log = get_result(_oof_df, fold, best_train_loss, best_val_loss)\n",
    "            output_log = pd.concat([output_log, df_epoch_scores, _output_log])\n",
    "\n",
    "    oof_df = oof_df.reset_index(drop=True)\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    _output_log = get_result(oof_df, 'OOF', np.mean(train_loss_list), np.mean(val_loss_list))\n",
    "    output_log = pd.concat([output_log, _output_log])\n",
    "    output_log.to_csv(CFG.OUTPUT_DIR+f\"{model_name}-{CFG.file_name}.csv\", index=False)\n",
    "    oof_df.to_pickle(CFG.OUTPUT_DIR+'oof_df.pkl', protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18dd8c-0d69-451f-98cb-c2c1abba3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.TO_KAGGLE:\n",
    "    UPLOAD_DIR = CFG.OUTPUT_DIR\n",
    "    EX_NO = f\"{model_name}{CFG.file_name}\" # 実験番号などを入れる、folderのpathにする\n",
    "    USERID = 'your_id'\n",
    "\n",
    "\n",
    "    def dataset_upload():\n",
    "        import json\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "        id = f'{USERID}/{EX_NO}'\n",
    "\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata['id'] = id\n",
    "        dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "        dataset_metadata['title'] = f'{EX_NO}'\n",
    "\n",
    "        with open(UPLOAD_DIR +'dataset-metadata.json', 'w') as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "\n",
    "        # データセットがない場合\n",
    "        if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
    "            api.dataset_create_new(folder=UPLOAD_DIR,\n",
    "                                   convert_to_csv=False,\n",
    "                                   dir_mode='skip')\n",
    "            \n",
    "            \n",
    "             #フォルダーを削除\n",
    "            if f'{USERID}/{EX_NO}' not in [str(d) for d in api.dataset_list(user=USERID, search=f'\"{EX_NO}\"')]:\n",
    "                remove_files = glob.glob(OUTPUT_DIR+\"*\")\n",
    "                remove_files.remove(OUTPUT_DIR+\"oof_df.pkl\")\n",
    "                for file in remove_files:\n",
    "                    os.remove(file)\n",
    "                print(\"folder upload\")\n",
    "                            #apiコマンドを書き込む\n",
    "                f = open(f'{model_name}_api_command.txt', 'a')\n",
    "                api_command = f\"!kaggle datasets download -d hiroki8383/{EX_NO}\\n\"\n",
    "                f.write(api_command)\n",
    "                f.close()\n",
    "            else:\n",
    "                print(\"folder not upload\")\n",
    "            \n",
    "            \n",
    "        # データセットがある場合→更新されない場合がある（後で原因追及)\n",
    "        else:\n",
    "            print(\"this folder exsits\")\n",
    "            # api.dataset_create_version(folder=UPLOAD_DIR,\n",
    "            #                            version_notes='update',\n",
    "            #                            convert_to_csv=False,\n",
    "            #                            delete_old_versions=False,\n",
    "            #                            dir_mode='zip')\n",
    "    dataset_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bba6c6-1fc6-4f8d-a907-670a7ab9e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.debug:\n",
    "    def to_write_score(CFG):\n",
    "        df = pd.read_csv(CFG.score_path)\n",
    "        def get_result2(oof_df):\n",
    "                labels = oof_df[CFG.target_cols].values\n",
    "                preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
    "                score, scores = get_score(labels, preds)\n",
    "                LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n",
    "                return score,scores\n",
    "\n",
    "        score,scores = get_result2(oof_df)\n",
    "        name = \"-\".join(OUTPUT_DIR.split(\"/\")[-4:-2])\n",
    "        base = {\"name\":name,\"score\":score,\"memo\":CFG.MEMO} \n",
    "        base.update(dict(zip(CFG.target_cols,scores)))\n",
    "        df = df.append(base,ignore_index=True)\n",
    "        df.to_csv(CFG.score_path,index=False)\n",
    "    to_write_score(CFG)\n",
    "    \n",
    "df = pd.read_csv(CFG.score_path)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.347487,
   "end_time": "2022-11-11T06:13:06.130510",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-11T06:12:26.783023",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1091895a476f464b835f26c80d699e9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_edd8b9d28b124eab9d9f29e1ea8f47dc",
       "placeholder": "​",
       "style": "IPY_MODEL_788e17e7d5224da7accd4f6c07d1d90c",
       "value": "Downloading: 100%"
      }
     },
     "10cc4a6ea4634108b00f3a2fd5a63e5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "166c33eda8dc46cda76f50053888af13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9d040c6671ae4c60b021f4e8a0c9451f",
       "placeholder": "​",
       "style": "IPY_MODEL_8e08f1513e4b4bf1bcb7f9e470339b5d",
       "value": " 579/579 [00:00&lt;00:00, 21.5kB/s]"
      }
     },
     "1c0aac6154d1486a9526b52ec010b8da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f4f92a14bcd45aa9d79affc714d28aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "33cdd914b8794dc486baf7fd85041b13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a79897b240e4ac2a78979e61a57bdf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bf5baa2492745c1aee85d9ca7202f32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5c3d96ee6d7a437fbcfe2c2d5fe4ae9b",
       "placeholder": "​",
       "style": "IPY_MODEL_f03efc83b5e24f459769375928439da2",
       "value": "100%"
      }
     },
     "3c7c0fe937d04736950f493bdc38d11d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "42e2b232cd104924b1ce885b778b4129": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4a4f4e661aeb4790b83b89eb46523420": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4adec9f561a544e68ee7d1edb427fac4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5283e532caaa48b18e0ce84e695a9640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9b944f0c1790404e8a549510cb517aa4",
       "max": 579,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fa5a0cdc52fb4cca951a47d42f19981b",
       "value": 579
      }
     },
     "550a7832f1744743aba094ee34417675": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_33cdd914b8794dc486baf7fd85041b13",
       "max": 2464616,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a879a3b4a0624ba88b1e1d51ebb58077",
       "value": 2464616
      }
     },
     "58f3913d9ad04745a7c42b92dceb1985": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c3d96ee6d7a437fbcfe2c2d5fe4ae9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62636e6b8ca446ea91e8663aaa41a841": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a79897b240e4ac2a78979e61a57bdf7",
       "placeholder": "​",
       "style": "IPY_MODEL_42e2b232cd104924b1ce885b778b4129",
       "value": "Downloading: 100%"
      }
     },
     "65586b8daceb424d94e2bdd9ec28776e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "788e17e7d5224da7accd4f6c07d1d90c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a5a06b92984427b9f2f7343c65f0878": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83de2ae5aab944df9b04596709c32927": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_97681a158e734e9795e982548ae9c80a",
       "max": 52,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f4a09cc8d22e4c8daa73e28a95119eab",
       "value": 52
      }
     },
     "8e08f1513e4b4bf1bcb7f9e470339b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "92c6635a3f3e4413bf5e7382bb03594b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "97681a158e734e9795e982548ae9c80a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b944f0c1790404e8a549510cb517aa4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d040c6671ae4c60b021f4e8a0c9451f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d0d9211a766488e906cc8530ec0ec8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a5a06b92984427b9f2f7343c65f0878",
       "placeholder": "​",
       "style": "IPY_MODEL_accb9da32d79417980b3b9bd128b006c",
       "value": "Downloading: 100%"
      }
     },
     "a879a3b4a0624ba88b1e1d51ebb58077": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "accb9da32d79417980b3b9bd128b006c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b70bb3c4a28c4dfc99605ff0939222bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9d0d9211a766488e906cc8530ec0ec8d",
        "IPY_MODEL_5283e532caaa48b18e0ce84e695a9640",
        "IPY_MODEL_166c33eda8dc46cda76f50053888af13"
       ],
       "layout": "IPY_MODEL_4a4f4e661aeb4790b83b89eb46523420"
      }
     },
     "c42c40480c6a4698ac54414630f8f1ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db137b7027724ef19419dc4690c182fe",
       "placeholder": "​",
       "style": "IPY_MODEL_3c7c0fe937d04736950f493bdc38d11d",
       "value": " 2.35M/2.35M [00:00&lt;00:00, 3.28MB/s]"
      }
     },
     "cc24ee6f778e4b93bcde025d965c90fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10cc4a6ea4634108b00f3a2fd5a63e5c",
       "placeholder": "​",
       "style": "IPY_MODEL_e31e9e506f344931a5729455c9a99953",
       "value": " 3911/3911 [00:06&lt;00:00, 703.85it/s]"
      }
     },
     "cd0c10df137145649fd408daf78c011f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62636e6b8ca446ea91e8663aaa41a841",
        "IPY_MODEL_83de2ae5aab944df9b04596709c32927",
        "IPY_MODEL_fb44d082374f4a179e6788f657a97aad"
       ],
       "layout": "IPY_MODEL_1c0aac6154d1486a9526b52ec010b8da"
      }
     },
     "d3713a7be7e2453398500ccd1d1bbfec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8474a2abd2642c6a330952df1d04600": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1091895a476f464b835f26c80d699e9d",
        "IPY_MODEL_550a7832f1744743aba094ee34417675",
        "IPY_MODEL_c42c40480c6a4698ac54414630f8f1ef"
       ],
       "layout": "IPY_MODEL_4adec9f561a544e68ee7d1edb427fac4"
      }
     },
     "d94c00f20aaf4b368f11154d86931b0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3bf5baa2492745c1aee85d9ca7202f32",
        "IPY_MODEL_dd25ec2004404f3e82e7541528157eaf",
        "IPY_MODEL_cc24ee6f778e4b93bcde025d965c90fa"
       ],
       "layout": "IPY_MODEL_65586b8daceb424d94e2bdd9ec28776e"
      }
     },
     "db137b7027724ef19419dc4690c182fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd25ec2004404f3e82e7541528157eaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_58f3913d9ad04745a7c42b92dceb1985",
       "max": 3911,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92c6635a3f3e4413bf5e7382bb03594b",
       "value": 3911
      }
     },
     "e31e9e506f344931a5729455c9a99953": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "edd8b9d28b124eab9d9f29e1ea8f47dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f03efc83b5e24f459769375928439da2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f4a09cc8d22e4c8daa73e28a95119eab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fa5a0cdc52fb4cca951a47d42f19981b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fb44d082374f4a179e6788f657a97aad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3713a7be7e2453398500ccd1d1bbfec",
       "placeholder": "​",
       "style": "IPY_MODEL_2f4f92a14bcd45aa9d79affc714d28aa",
       "value": " 52.0/52.0 [00:00&lt;00:00, 1.72kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
